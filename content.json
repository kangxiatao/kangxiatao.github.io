{"posts":[{"title":"AI工具箱","text":"AnoI 首先我们得承认一件事，在不久后的地球上，在人类的各行各业中，对AI工具的掌握远比对知识的掌握更重要。 刚接触神经网络那会我还在高呼人工不智能机器不学习，如今我只能对着大模型给出的结果大呼牛逼。 在此整理一些AI工具吧，也算一个简单的市场调研。新的赛道已经开辟了，等晚上去散个步，晨跑也行捏。 总结 总结写在前面。 额，暂时没有总结。 想法 压缩和加速 Alpaca-Lora Deep Speed Chat 翻译 ChatGPT + WHISPER AI 应用（小程序） 语言模型 + 小游戏 机器人（助手之类，记事本、记账、、） 语言模型 + 绘画模型 语言模型系列工具 ChatGPT OpenAI的ChatGPT到了人尽皆知的地步，说的搞笑一点，做ChatGPT的中介都有很大的市场。 以GPT开发的工具不胜枚举，明争暗斗。 Copilot 最开始还只是用在搜索引擎上，所谓New Bing。现在已经嵌入到微软全家桶了，称为Copilot，目前来说微软的布局是无敌的。 Copilot也是一个代码助手。 实用的工具 Prompt ChatGPT调教 (挺有用) Prompt 插件 浏览器插件teamsmart 调用ChatGPT API + Prompt细分到各领域，用起来挺不错 ChatDOC 免费版，支持自己的API key ChatPaper 除了论文总结，相关的还有论文润色、AI审稿、AI审稿回复等功能 Paperade 从论文中搜索创意和想法，用起来一般，论文含金量低。 基于ChatGPT的一些办公服务 太多了，没有试用，感觉效果一般 其他 大多是一些调教过的ChatGPT，或国内镜像，偏娱乐，不稳定。 LaMDA 谷歌的LaMDA比ChatGPT早一年，但是ChatGPT的大规模开放直接从学术圈冲向了民众，而谷歌还存在AI伦理纠纷，输的有点麻。 Bard 因为Google和Bing不是一个量级，谷歌部署Bard的成本远大于微软的New Bing，后续的Bard也是备受争议。 LLaMA Meta AI最新发布的大语言模型 现在基于LLaMA的研究和应用已经不可胜数了。 文心一言 百度，需要申请资格 通义千问 达摩院，需要申请资格 目前来看似乎比文心一言效果更好，毕竟之前他们也有不错的BERT模型应用。 其他 另外我比较看好华为和腾讯的大模型，毕竟他们都有云计算服务，软硬件实力都有。 AI图像处理 图像领域是非常卷的，我知道的不多，但是必需提一手Segment Anything Model，分割一切。 没有特意去搜集了，收藏了几个：换脸FaceHub，人脸修复restorePhotos，面孔动画Deep Nostalgia，抠图Airbrush。 AI绘画工具 Image Creator 微软AI绘画 NovelAI 一直很火，开源，相关的教程非常多 Midjourney 据说AI 绘图里的实用性最强 NVIDIA Canvas 推出好多年了，不知道现在效果怎么样 ERNIE-ViLG AI 文心 Draft 基于Stable Diffusion的AI绘图 绘画模型和应用太多了，我也不是很了解 AI建模，AI视频 有看到过一些效果比较好的，没实际用过，暂时略。","link":"/2023/04/15/16/clgj6ojir0000ssik2k17fd5t/"},{"title":"AI市场调研","text":"AyesI 试看将来的环球，必将是AI的世界。 AI市场调研 现状 市场 大语言模型的AI之战 AI办公助手微软近乎垄断 基于GPT开发的工具不胜枚举 缺口 国内使用门槛高 各种AI工具效果一般 概念远高于实际应用 知名度高但用户群体少 问题 大部分工具是ChatGPT API + Prompt 提供服务成本高，没有盈利空间 用户群体没有付费意识且要求高 同类产品饱和度高，竞争激烈 智能教育 应试教育和高等教育的AI工具 AI学习辅助 文化课素材整理 教案设计 AI文献工具 论文总结 AI审稿 AI润色 AI检索工具 教学 AI教学平台 AI的基础教学 AI应用层面的教学 神经网络框架 模型部署 硬件基础 生活助手 AI健康 医疗服务 健康管理 营养指导 AI娱乐 AI创作 AI检索和推荐 AI出行 AI旅行建议 AI记事 记事本 记账 记工 AI助残 AI助听器 AI眼镜 AI翻译 AI小语种翻译 AI小语种口译 语言模型 + 翻译模型 AI语言学习工具 AI游戏 语言模型 + 小游戏 语言模型 + 绘画模型 + 小游戏 强化学习小游戏 AI游戏结合娱乐和教学 办公助手 Copilot Word助手 PPT助手 Excel助手 会议助手 ... 智能客服 提供专业领域的智能问答服务 智能客服系统的AI辅助 提示 评估 智能家居 智能硬件 AI语音助手 智能居家场景 医疗助手 AI医疗诊断系统 可行方向 发展规划 软件产品 服务平台 基本 用户管理 收费系统 AI教学平台 深度学习教学 开源模型讲解 AI工具导航 AI资讯 ChatGPT助手 平台 浏览器插件 小程序 功能 AI记事工具 AI检索工具 AI翻译工具 AI游戏 趣味对话小游戏 绘画游戏 AI玩游戏 娱乐+教学 需面临的问题 技术问题 算法设计 模型压缩（Alpaca-Lora） 模型加速（Deep Speed Chat） 成本问题 服务成本高，收入少 付费用户少 需要依靠广告收入 智能硬件 AI教学软硬件设施 竞赛支持 电子设计竞赛 智能车竞赛 硬件+算法 开源方案讲解 AI开发套件+程序设计 开发板 树莓派、Jetson系列 NXP、STM32系列 其他硬件 智能车、机械臂等套件 程序设计 各类算法 模型压缩部署 残障人士智能设备 AI拐杖 AI盲镜 AI助听器 需面临的问题 工作量大 需要硬件团队 需要运营网店 需要规划产线 自媒体 全平台 宣传推广 公司趣事 构建用户圈","link":"/2023/04/16/12/clgj6ojj10001ssik4bpe28e9/"},{"title":"GitHub和Hexo搭建博客","text":"0，前言 Hexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以方便的生成静态网页托管在GitHub上，是搭建博客的首选框架。 搭建步骤： GitHub创建个人仓库 安装Git 安装Node.js 安装Hexo 推送网站 1，GitHub仓库创建 和 git安装 这两个很简单一笔带过，唯一要注意的是仓库名字的固定写法：用户名.github.io，否则域名会变。 2，安装 Node 和 npm Node 是服务器端运行 Js 代码的引擎；npm 则是依赖包管理工具，可以轻松安装工具和代码类库。 Node 中文网 http://nodejs.cn/download/ Windows上没什么好说的，Ubuntu上的步骤如下，Windows控制台安装也一样。 ubuntu上安装 1sudo apt install npm 查看版本检测是否安装成功 1npm -v 修改npm的资源镜像链接 1npm config set registry http://registry.npm.taobao.org 安装serve 1npm i -g serve 在文件夹目录中启动serve即可搭建一个 web 服务器，以支持 http 协议访问。 值得注意的是，如果搭建服务器的话Ubuntu需要开放端口： 查看已经开启的端口 1sudo ufw status 打开端口 1sudo ufw allow 9123 开启防火墙 1sudo ufw enable 重启防火墙 1sudo ufw reload 3，Hexo安装和使用 Hexo安装也很简单，这里记一些指令： 安装和初始化 123npm install hexo-cli -g # 全局安装Hexonpm update hexo -g # 升级hexo init # 初始化博客（在当前目录新建一个博客） 命令简写 12345678910hexo n &quot;我的博客&quot; == hexo new &quot;我的博客&quot; # 新建文章hexo g == hexo generate # 生成hexo s == hexo server # 启动服务预览hexo d == hexo deploy # 部署hexo server # Hexo会监视文件变动并自动更新，无须重启服务器hexo server -s # 静态模式hexo server -p 5000 # 更改端口hexo server -i 192.168.1.1 # 自定义 IPhexo clean # 清除缓存，若是网页正常情况下可以忽略这条命令 4，推送网站 在blog根目录里的_config.yml文件称为站点配置文件，另外还有主题配置文件，主题抄好之后就都靠自己魔改了。 _config.yml文件的设置 1234deploy: type: git branch: master repo: https://github.com/kangxiatao/kangxiatao.github.io.git 其实就是给hexo d 这个部署命令做相应的配置，d是deploy的缩写，让hexo知道你要把blog部署在哪个位置，很显然，我们部署在我们GitHub的仓库里。 安装Git部署插件： 1npm install hexo-deployer-git --save 生成和部署网站： 12hexo g hexo d 此时博客已经上线了，也可以先用hexo s在本地预览。 5，更新博客 在\\blog\\source\\_posts文件夹下添加md文件，编辑完之后，更新到GitHub就行，也就是生成和部署网站的步骤，over，我要魔改UI去了。 6，支持mathjax hexo默认的渲染器是marked，并不支持mathjax。kramed是在marked基础上修改的，支持了mathjax。 工程目录下安装kramed 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 修改配置文件 到主题配置文件_config.yml，找到mathjax，将其修改为true 12mathjax: enable: true 文章渲染标签 为加快渲染速度，渲染器只会在标签中有mathjax: true的文章中使用利用mathjax渲染。 123456789---title: 强化学习（Reinforcement Learning）date: 2021-01-27 00:00:58mathjax: truecategories: 学习日志tags:- 强化学习- 神经网络--- 999，Error server : 无法加载文件，因为在此系统上禁止运行脚本 以管理员身份打开windows powershell 输入set-ExecutionPolicy RemoteSigned","link":"/2021/06/28/22/clgj6ojj80004ssikeiibdieu/"},{"title":"Docker笔记","text":"千万不要用docker 嘿嘿，docker真香，🤤🤤 docker note 镜像和容器操作 移除镜像 docker rmi 85e62d9e0586 打包容器 docker commit 7b2d0ec9a289 deepidea:kxt 保存镜像 docker save &gt; synergy.tar deepidea:synergy 集群 部分指令 12345678# 创建swarmdocker swarm init --advertise-addr=192.168.1.30# 获取新的token标记文本docker swarm join-token manager# 查看节点列表docker node ls # 离开集群docker swarm leave --force 示例 12345678910# 创建swarmdocker swarm init --advertise-addr=192.168.1.30# 超过24小时需要重新获取tokendocker swarm join-token manager# 用输出的token加入到swarmpass# 为容器建立集群网络docker network create --driver=overlay --attachable my-overlay-net# docker run时选到集群网络中即可pass 其他 访问权限 xhost local:root xhost + 新建容器命令行 docker exec -it melodic_world bash 获取容器长ID docker inspect -f '{{.ID}}' px4_test 复制文件到docker中 docker cp 文件路径 容器长ID:容器文件路径 dockerfile dockerfile 构建环境，塔门说PX4子模块有问题，我没试 12345678910111213141516171819202122232425首先进入robot/PX4_Firmwaregit clone http://192.168.1.10:3000/robot/PX4_Firmware.git克隆后进入git checkout xtdrone/dev-v1.13.2文件就显示完毕了点击.gitmodules文件修改[submodule &quot;Tools/sitl_gazebo&quot;]的地址[submodule &quot;Tools/sitl_gazebo&quot;]path = Tools/sitl_gazebourl = http://192.168.1.10:3000/robot/PX4-SITL_gazebo.gitbranch = master保存退出后git submodule update --init --recursive之后把PX4_Firmware和GeographicLib放入Dockerfile同级目录中运行docker build -t name .指令，其中name为你自己的docker名字在run_melodic_px4_world.sh文件中修改--volume=&quot;/home/xxx/catkin_ws/src:/root/catkin_ws/src&quot; \\，xxx为你自己的用户名使用docker network create --driver=bridge --subnet=10.8.0.2/16 locros创建docker网络对于无法启动gazebo这一问题，用xhost local:root解锁权限，再./run_melodic_px4_world.sh测试 docker gpu 123456distribution=$(. /etc/os-release;echo $ID$VERSION_ID)curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.listsudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkitsudo systemctl restart docker px4 gazebo note test 12345678910111213141516# 启动仿真roslaunch synergy multi_vehicle_v1.launch# 无人机控制docker exec -it px4_test bashcd ~/catkin_ws/src/synergy/scripts/python3 control_mul.py # 无人车控制docker exec -it px4_test bashcd ~/catkin_ws/src/synergy/scripts/self_driving/python2 ugv_hector_driving.py # 图传和轨迹docker exec -it px4_test bashrviz rviz 换源 -i https://pypi.tuna.tsinghua.edu.cn/simple PX4 1.13版本修改 https://blog.csdn.net/weixin_44537885/article/details/125946076 gazebo问题 export LIBGL_ALWAYS_INDIRECT=1 sudo apt install libnvidia-gl-525 linux note 权限 chmod 777 install.sh 当前路径 pwd 环境变量问题 全局 ./etc/profile (source /etc/profile) 用户 ~/.bashrc AppImage问题 Ubuntu 22.04 缺少 FUSE（用户空间中的文件系统）库 sudo apt install libfuse2","link":"/2023/04/10/22/clgj6ojja0005ssik606u841l/"},{"title":"Git使用手册","text":"前言 总是记不得git的一些指令，查一次用一次，做个笔记吧。 Git 基本操作 创建仓库命令 git init 初始化仓库 git clone 拷贝一份远程仓库，也就是下载一个项目。 提交与修改 git add 添加文件到仓库 git status 查看仓库当前的状态，显示有变更的文件。 git diff 比较文件的不同，即暂存区和工作区的差异。 git commit 提交暂存区到本地仓库。 git reset 回退版本。 git rm 删除工作区文件。 git mv 移动或重命名工作区文件。 提交日志 git log 查看历史提交记录 git blame &lt;file&gt; 以列表形式查看指定文件的历史修改记录 远程操作 git remote 远程仓库操作 git fetch 从远程获取代码库 git pull 下载远程代码并合并 git push 上传远程代码并合并 Git Github 添加SSH公钥：基于SSH协议的Git服务，好比是仓库的钥匙 ssh-keygen -t rsa -C \"账号（如：github邮箱）\" cat ~/.ssh/id_rsa.pub 得到key值，给到相应平台 验证是否成功: ssh -T git@github.com 初始化本地仓库（要上传的文件根目录）：git init 本地连接github远程仓库：git remote add origin [github上仓库的地址] 移除连接：git remote rm origin 如是https，可解除https的ssl的凭证git config --global http.sslVerify false 将github上的文件克隆到本地，保持本地和远程的github的文件保持一致：git pull --rebase origin main git add 文件名 or git add . 添加所有的文件 将代码提交到本地仓库：git commit -m \"提交说明\" 将本地仓库所有上传到github上管理：git push -u origin main 第一次推送，加上了-u参数，Git本地和远程关联起来，在以后的推送或者拉取时就可以简化命令。 加-f是强制上传（危险操作） 使用Git上传到多个Github仓库 一个Github对应一个SSH公钥 在~/.ssh/下创建config文件用于映射 1234567891011# 799802172@qq.comHost github.comHostName github.comUser gitIdentityFile ~/.ssh/id_rsa# 2072483140@qq.comHost ano.github.comHostName github.comUser gitIdentityFile ~/.ssh/id_rsa_anoo 将SSH key的密钥加入ssh agent中 添加对应的GitHub的邮箱和名称（上传仓库的作者）","link":"/2021/09/10/18/clgj6ojjb0006ssik91ymgwwe/"},{"title":"Google Colaboratory的配置和使用","text":"0. 前言 最近一直在炼丹，之前老师租的服务器上千块钱一个月，显卡也很一般，Google完全免费的Colaboratory，通常给到的GPU资源是Tesla T4，TPU也是能免费用的，8个核，相当于8个GPU分布式训练，快的飞起，就是用起来程序上很麻烦。开通Colab Pro每月就9.9刀，同时可以多开，拿到的GPU一般的Tesla V100和P100，相比T4快了不少，V系类算力更高些。 谷歌在环境方便做了很好的适配，兼容性很高，用了一段时间之后，只能说Google一次又一次让我感到震惊，友好的UI和全局中文，添加了很多方便的可视化操作，从使用体验上来说就已经无敌了，这就是资本的力量吗。 当然Colab有使用限制，每次运行最多12个小时，不过我Pro三个会话好像通常不到6个小时，做些小模型小数据集的实验还是比自己的服务器划算一些. 1. 创建笔记本 新建Google Colaboratory 如果Colaboratory不存在，转到页面https://colab.research.google.com/notebooks/welcome.ipynb 点击左上角的“复制到云盘”，重新进入自己的云盘新建选项中就会出现Colaboratory。 然后可以新建ipynb文件，也就和jupyter notebook类似。 在ipynb中可以对当控制台使用，在指令面前加\"!\"就行。 2. 选择GPU/TPU 在“修改”=&gt;“笔记本设置” 中可以选择GPU，然后在右边有连接选项 检测GPU情况： 123# 检测GPU情况import tensorflow as tftf.test.gpu_device_name() 查看显卡信息： 1!nvidia-smi Google, yyds 3. 挂载Google Drive 在左边的控制栏中有直接的挂载Drive的选项，也可以通过drive.mount添加。 12from google.colab import drivedrive.mount('/content/drive/') 4. 更改运行目录 更改到目录之后可以直接!python youcode.py运行python程序。 12import osos.chdir(&quot;/content/drive/MyDrive/MyCode&quot;) 5. 切换tensorflow环境 1%tensorflow_version 1.x 6. Google，暂时的神","link":"/2021/01/07/00/clgj6ojjf0009ssikh1jb2ipr/"},{"title":"NLP 自然语言处理（Natural Language Processing）","text":"前言 跟着师兄做知识图谱相关课题，果然知识图谱还是🉐和NLP结合，那就来把，先过一遍NLP。 早期的自然语言处理是基于规则来建立词汇、句法语义分析。 后来的统计自然语言处理基于人工定义的特征建立机器学习系统。 现在基本上都是神经网络自然语言处理，之前的NLP方法简单做了些了解，接下来的学习就是从神经网络自然语言处理开始了。 神经网络自然语言处理的基本思想 理解词语 词向量 把词映射到空间中，根据夹角、距离和长短等判断词的相似性。 Continuous Bag of Words (CBOW) 前后的词预测中间的词 Skip-Gram 中间的词预测前后的词 理解句子 句向量 通过模型，得到的机器对于一句话的理解，对于这个理解，也就是向量，使用的方法不止一种。 Encoding 得到词向量之后，使用神经网络做复杂乘法运算得到句向量，也就是把多个词空间向量通过神经网络映射到另一个空间做句向量。 Encoding过程类似压缩的过程，将大量复杂的信息，压缩成少量经典的信息，通过这个途径找到信息的精华部分。 Decoding Encoding得到的句向量就是机器对句子的理解，那么可以用另一个神经网络对句向量做各种各样的解码操作。 简而言之，Encoder负责理解上文，Decoder负责将思考怎么样在理解的句子的基础上做任务。 Seq2Seq seq2seq属于encoder-decoder结构的一种，常见的encoder-decoder结构，基本思想就是利用两个RNN，一个RNN作为encoder，另一个RNN作为decoder。encoder负责将输入序列压缩成指定长度的向量，这个向量就可以看成是这个序列的语义，这个过程称为编码，而decoder则负责根据语义向量生成指定的序列，这个过程也称为解码。 循环神经网络 RNNs的目的是用来处理序列数据，不只是在NLP领域取得巨大成功，在其他领域也有一席之地，比如图像描述生成和路径判断等也有不错的效果。 Simple RNN 也就是基础的RNN网络，也被称为Vanilla RNN Bidirectional RNN 双向的RNN，上下叠加在一起组成的，相当于前后的序列信息加在一起。 Deep (Bidirectional) RNN 顾名思义，更深层的结构，为了更强的表达能力 Echo State Network 回声状态网络，主要的特点就是它有一个“存储库”，使用大规模随机连接的循环网络取代经典神经网络中的中间层，一般称为reservoir，来存储相关的信息和保存时间特性。 LSTM (Long Short-Term Memory) 简单来说增加了一个传输状态，用于记录长期的信息，内部有忘记、选择记忆、和输出三个阶段。 Gated Recurrent Unit GRU是对LSTM的一个简化，只使用了一个更新门。 BiLSTM(Bi-directional LSTM) 双向LSTM 注意力机制 Attention机制最早提出是在视觉领域，2014年Google Mind发表了《Recurrent Models of Visual Attention》，采用了RNN模型，并加入了Attention机制来进行图像的分类。 2015年，Bahdanau等人在论文《Neural Machine Translation by Jointly Learning to Align and Translate》中，将attention机制首次应用在nlp领域，其采用Seq2Seq+Attention模型来进行机器翻译。 2017年，Google 机器翻译团队发表的《Attention is All You Need》成了划时代的论文，完全抛弃了RNN和CNN等网络结构，而仅仅采用Attention机制来进行机器翻译任务，取得了很好的效果，注意力机制也成了研究热点。 抽象理解 从注意力三个字就可以抽象理解到，输入信息有很多特征，学习的时候不仅是特征提出，也要做重要程度的标记，或者说特征权重，这就是注意力机制。 Seq2Seq Attention decoder中的信息定义为Query，encoder中的信息定义为Key，Query和Key通过多种计算方式得到权重值，生成一个注意力的context，再和之前的context结合，最后decoder输出结果。 笼统来说就是decoder每预测一个词，都拿着decoder现在的信息去和encoder所有信息做注意力的计算。基本上所有的attention都采用了这个原理，只不过算权重的函数形式可能会有所不同，但想法相同。 self-attention 自注意力的思想很简单，建立两两之间的注意力权重，作用时与特征信息线性加权。 Multi-head attention 多头注意力与自注意力的核心原理差不多，由多个自注意力组成，相当于从多个角度关注。 Transformer Transformer也是由 Encoder-Decoder 结构组成，但不是RNN中的Encoder-Decoder，简单说就是直接对词向量使用注意力。(Query, Key, Value) 参考：The Illustrated Transformer","link":"/2021/09/08/16/clgj6ojjg000assikh8smfhbf/"},{"title":"ROS与Gazebo联合仿真平台搭建","text":"软硬件规格 1、装有Ubuntu 18.04的电脑（最好不要用虚拟机） 2、多机仿真对cpu要求很高，最好有显卡 3、CMake请使用最新版本！！！！ 一、依赖安装 1、先安装python运行环境 2、安装以下依赖包 1sudo apt install ninja-build exiftool ninja-build protobuf-compiler libeigen3-dev genromfs xmlstarlet libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev python3-pip gawk 12pip install pandas jinja2 pyserial cerberus pyulog==0.7.0 numpy toml pyquaternion empy pyyaml pip3 install packaging numpy empy toml pyyaml jinja2 pyargparse 如果出现如下报错情况，可先更新 setuptools 和 pip 123456789101112Collecting pandas Using cached https://files.pythonhosted.org/packages/64/f1/8fdbd74edfc31625d597717be8c155c6226fc72a7c954c52583ab81a8614/pandas-1.1.2.tar.gz Complete output from command python setup.py egg_info: Traceback (most recent call last): File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; File &quot;/tmp/pip-build-qtvsjq8t/pandas/setup.py&quot;, line 349 f&quot;{extension}-source file '{sourcefile}' not found.\\n&quot; ^ SyntaxError: invalid syntax ----------------------------------------Command &quot;python setup.py egg_info&quot; failed with error code 1 in /tmp/pip-build-qtvsjq8t/pandas/ 123#若未报错不需要输入这两行命令pip install --upgrade setuptoolspython -m pip install --upgrade pip 特别提醒，在整个环境配置中，不要轻易使用 apt-get autoremove，详见慎用apt-get autoremove 建议退出conda环境再编译 二、ROS安装 需注意 Ubuntu 16.04对应Kinetic，18.04对应Melodic，20.04对应Noetic。 安装步骤可见ROS官网 如果您的网络环境不佳，可以用fishros工具一键安装。 方法一： fishros工具一键安装 使用wget命令进行ros安装(此方法会默认配置好环境，如果需要换源，请再次执行该指令): 1wget http://fishros.com/install -O fishros &amp;&amp; . fishros 根据工具完成ros的安装后，再次使用上述wget命令来配置rosdep。rosdep是ros一个命令行工具，用于安装系统依赖，具体地说，就是ros包的依赖。 安装rosinstall: 1sudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential 初始化rosdep: 1rosdepc update 安装完成，测试 1roscore 如果出现如下输出,则说明安装成功。 1234567891011121314151617181920212223242526sliver@zyc:~$ roscore... logging to /home/sliver/.ros/log/8df53f9e-b89c-11ed-a703-38ca84472d52/roslaunch-zyc-13243.logChecking log directory for disk usage. This may take a while.Press Ctrl-C to interruptDone checking log file disk usage. Usage is &lt;1GB.started roslaunch server http://zyc:43825/ros_comm version 1.14.13SUMMARY========PARAMETERS * /rosdistro: melodic * /rosversion: 1.14.13NODESauto-starting new masterprocess[master]: started with pid [13272]ROS_MASTER_URI=http://zyc:11311/setting /run_id to 8df53f9e-b89c-11ed-a703-38ca84472d52process[rosout-1]: started with pid [13302]started core service [/rosout] 如果之前没有catkin_ws，则需要新建工作空间，之后除去PX4仿真环境启动外，其余ROS相关工程在此工作空间下管理。 1234mkdir -p ~/catkin_ws/srcmkdir -p ~/catkin_ws/scriptscd catkin_ws &amp;&amp; catkin init # 使用catkin_make话，则为cd catkin_ws/src &amp;&amp; catkin_init_workspacecatkin build # 使用catkin_make话，则为 cd .. &amp;&amp; catkin_make catkin build需要先装catkin-tools（sudo apt install python3-catkin-tools），其与catkin_make的区别见Migrating from catkin_make，建议使用catkin build，因为它分别编译各个功能包，而catkin_make则是同时编译整个工作空间，当工作空间中功能包过多时，容易出现问题。 方法二： 安装见ROS官方网站：http://wiki.ros.org/Installation/Ubuntu 或者参考教程:https://blog.csdn.net/qq_44830040/article/details/106049992（这个教程是用的国内源安装，虽然可以使用ros，但是可能在和其他的一起使用时出现问题例如darknet_ros，虽然国内源下载会快很多，但还是建议从官网下载） 注意：Ubuntu18.04可以直接全部安装（即指令 sudo apt-get install ros-melodic-desktop 即对于ROS Melodic，选择desktop-full的方式安装,这将同时安装Gazebo9和感知相关库）但是我个人建议18.04的也不进行全部安装，直接安装的gazebo9.0存在缺陷可能在后面出现问题，建议也是选择安装desktop，然后在下面的步骤中安装gazebo9.13或者以上。Ubuntu16.04（ROS Kinetic）选择destop否则安装gazebo7无法进行后续仿真。 三、Gazebo和XTDrone安装 首先卸载之前的Gazebo 123sudo apt-get remove gazebo* sudo apt-get remove libgazebo*sudo apt-get remove ros-melodic-gazebo* #kinetic noetic对应修改 Gazebo安装见Gazebo官网,需注意以下三点。 1、选用Alternative installation: step-by-step的安装方式，安装最新的gazebo9，不要安装gazebo11 2、如果安装有依赖问题，可以使用sudo aptitude install gazebo9，选择合理的依赖解决办法（别把ROS删了） 3、按步骤装完Gazebo后，升级所有的包 sudo apt upgrade，这样能保证gazebo所有依赖版本一致 4、安装步骤如下 12345678910111213141516sudo sh -c 'echo &quot;deb http://packages.osrfoundation.org/gazebo/ubuntu-stable `lsb_release -cs` main&quot; &gt; /etc/apt/sources.list.d/gazebo-stable.list'cat /etc/apt/sources.list.d/gazebo-stable.list#如果出现deb http://packages.osrfoundation.org/gazebo/ubuntu-stable xenial main表示没问题# 设置键wget https://packages.osrfoundation.org/gazebo.key -O - | sudo apt-key add -# 这一步如果报错(见问题汇总,首先是否配置hosts,其次系统是否为ubuntu18.04)sudo apt-get update# 根据官方文档安装9最新版本sudo apt-get install gazebo9=9.1*# 升级包sudo apt upgrade# 测试roscore rosrun gazebo_ros gazebo #若能打开Gazebo说明Gazebo和ROS间的插件也安装成功。#输入gazebo --version也可以查看到gazebo的版本 XTDrone安装 XTDrone是基于PX4、ROS与Gazebo的无人机通用仿真平台。支持多旋翼飞行器（包含四轴和六轴）、固定翼飞行器、复合翼飞行器（包含quadplane，tailsitter和tiltrotor）与其他无人系统（如无人车、无人船与机械臂）。 XTDrone对Gazebo的ROS插件做了修改，因此需要源码编译。 首先装依赖 1sudo apt-get install ros-melodic-moveit-msgs ros-melodic-object-recognition-msgs ros-melodic-octomap-msgs ros-melodic-camera-info-manager ros-melodic-control-toolbox ros-melodic-polled-camera ros-melodic-controller-manager ros-melodic-transmission-interface ros-melodic-joint-limits-interface 然后编译（如果编译时还缺其他的依赖，同上方法安装），由于需要用到XTDrone的文件，需要先完成XTDrone源码下载。 1234cd ~git clone https://gitee.com/robin_shaun/XTDrone.gitcd XTDronegit submodule update --init --recursive 123cd ~/catkin_wscp -r ~/XTDrone/sitl_config/gazebo_ros_pkgs src/catkin build #开发者测试使用catkin_make会出问题，因此建议使用catkin build 编译成功后执行如下两条指令，判断gazebo_ros是否安装成功 1roscore 12source ~/catkin_ws/devel/setup.bashrosrun gazebo_ros gazebo 如果出现:ResourceNotFound: gazebo_ros，安装gazebo_ros就好了： 1sudo apt install ros-noetic-gazebo-ros-pkgs 下载models.zip 将该附件解压缩后放在~/.gazebo中，此时在~/.gazebo/models/路径下可以看到很多模型。如果不做这一步，之后运行Gazebo仿真，可能会缺模型，这时会自动下载，Gazebo模型服务器在国外，自动下载会比较久。 四、MAVROS安装 mavros是PX4官方提供的一个运行于ros下收发mavlink消息的工具 注意，mavros-extras一定别忘记装，否则视觉定位将无法完成 123456sudo apt install ros-kinetic-mavros ros-kinetic-mavros-extras # for ros-kineticsudo apt install ros-melodic-mavros ros-melodic-mavros-extras # for ros-melodicwget https://gitee.com/robin_shaun/XTDrone/raw/master/sitl_config/mavros/install_geographiclib_datasets.shsudo chmod a+x ./install_geographiclib_datasets.shsudo ./install_geographiclib_datasets.sh #这步需要装一段时间 最后的sudo ./install_geographiclib_datasets.sh 这步需要装一段时间,请耐心等待 五、PX4配置（1.11） 由于国内的github下载速度较慢，XTrone的作者们把固件和submodule同步到了gitee，如果嫌github慢，可以从gitee下载。 github下载 123456git clone https://github.com/PX4/PX4-Autopilot.gitmv PX4-Autopilot PX4_Firmwarecd PX4_Firmwaregit checkout -b xtdrone/dev v1.11.0-beta1git submodule update --init --recursivemake px4_sitl_default gazebo gitee下载 123git clone https://gitee.com/robin_shaun/PX4_Firmwarecd PX4_Firmwaregit checkout -b xtdrone/dev v1.11.0-beta1 后面步骤参考Ubuntu18.04下基于ROS和PX4的无人机仿真平台的基础配置搭建 有条件的建议科学上网下载。 六、安装地面站QGroundControl 点此安装链接。启动后,将出现下图 所示画面。 安装之前输入以下命令 12345sudo usermod -a -G dialout $USERsudo apt-get remove modemmanager -ysudo apt install gstreamer1.0-plugins-bad gstreamer1.0-libav gstreamer1.0-gl -ysudo apt install libqt5gui5 -ysudo apt install libfuse2 -y 安装_QGroundControl_： 下载QGroundControl.AppImage。 使用终端命令安装（并运行）： 12chmod +x ./QGroundControl.AppImage./QGroundControl.AppImage (or double click) 七、问题列表 安装ROS出现gpg: no valid OpenPGP data found. 问题 执行：curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add - 出现：gpg: no valid OpenPGP data found. 解决办法 将这条命令分两步执行。上述命令中有管道符号，curl是个类似下载的命令，因此尝试将上述命令分开两步执行。 1）curl -O https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc #该命令执行后在当前目录下保存一个ros.asc的文件 2）sudo apt-key add ros.asc #添加ros.asc github连接失败 443 ubuntu 20.04 | 解决 Connecting to raw.githubusercontent.com :443... failed: Connection refused 运行make px4_sitl_default gazebo报错 https://blog.csdn.net/wxc__CSDN/article/details/121018458 1234# 升级包sudo apt-get upgrademake clean make px4_sitl_default gazebo 找不到包: gazebo_ros https://blog.csdn.net/m0_50848587/article/details/113104907 1sudo apt install ros-melodic-gazebo-ros-pkgs fx4通讯失败:connected: false 查看环境变量 12345678# ros安装时设置source /opt/ros/noetic/setup.bash# px4配置source ~/catkin_ws/devel/setup.bashsource ~/PX4_Firmware/Tools/setup_gazebo.bash ~/PX4_Firmware/ ~/PX4_Firmware/build/px4_sitl_defaultexport ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/PX4_Firmwareexport ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/PX4_Firmware/Tools/sitl_gazebo 查看版本 12# 查询版本是否为9gazebo --version 如果版本不是9,则升级或降级版本为9 https://blog.csdn.net/JIEJINQUANIL/article/details/104056169 注意gazebo_ros_pkgs包和gazebo9-ros-control时要选择noetic版本 1$ sudo apt-get install ros-noetic-gazebo9-ros-pkgs ros-noetic-gazebo9-ros-control ROS包编译报错 No module named catkin_pkg.package 报错信息 12ImportError: &quot;from catkin_pkg.package import parse_package&quot; failed: No module named catkin_pkg.packageMake sure that you have installed &quot;catkin_pkg&quot;, it is up to date and on the PYTHONPATH. 解决方案 123cd /pip install catkin_pkgpip install rospkg ## gazebo有时候打不开报错 用ctrl+c关闭仿真进程，有可能没有把Gazebo的相关进程关干净，这样再启动仿真时可能会报错。如果出现这种情况，可以用killall -9 gzclient，killall -9 gzserver 这两个命令强行关闭gazebo所有进程。 12killall -9 gzclientkillall -9 gzserver ## darknet编译报错:/bin/sh: 1: nvcc: not found make: *** [obj/convolutional_kernels.o] Error 修改makefile 1NVCC = /usr/local/cuda-10.0/bin/nvcc ## undefined reference to cv::String::deallocate()' :::info image_opencv.cpp:(.text._ZN2cv6StringC2EPKc[_ZN2cv6StringC5EPKc]+0x30): undefined reference tocv::String::allocate(unsigned long)' /usr/bin/ld: obj/http_stream.o: in function MJPG_sender::write(cv::Mat const&amp;)': http_stream.cpp:(.text._ZN11MJPG_sender5writeERKN2cv3MatE[_ZN11MJPG_sender5writeERKN2cv3MatE]+0x1d6): undefined reference tocv::imencode(cv::String const&amp;, cv::_InputArray const&amp;, std::vector&lt;unsigned char, std::allocator &gt;&amp;, std::vector&lt;int, std::allocator &gt; const&amp;)' /usr/bin/ld: http_stream.cpp:(.text._ZN11MJPG_sender5writeERKN2cv3MatE[_ZN11MJPG_sender5writeERKN2cv3MatE]+0x1de): undefined reference to cv::String::deallocate()' /usr/bin/ld: http_stream.cpp:(.text._ZN11MJPG_sender5writeERKN2cv3MatE[_ZN11MJPG_sender5writeERKN2cv3MatE]+0x738): undefined reference tocv::String::deallocate()' collect2: error: ld returned 1 exit status make: *** [Makefile:169：darknet] 错误 1 ::: 理由暂未确定，但目前我们不需要调用摄像头，所以将opencv设置为1，可以解决该报错 运行roslaunch px4 mavros_posix_sitl.launch RLException: [mavros_posix_sitl.launch] is neither a launch file in package [px4] nor is [px4] a launch file name 1234# 在PX4目录下执行source Tools/setup_gazebo.bash $(pwd) $(pwd)/build/px4_sitl_defaultexport ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:$(pwd):$(pwd)/Tools/sitl_gazebo 运行github下载的无人车时出现：no such command [['/opt/ros/noetic/share/xacro/xacro.py' RLException: Invalid tag: Cannot load command parameter [robot_description]: no such command [['/opt/ros/noetic/share/xacro/xacro.py', '/home/lvrobot/ROSExample/src/ros_robotics/urdf/rrbot.xacro']]. Param xml is The traceback for the exception was written to the log file 原文件中为 1&lt;param name=&quot;robot_description&quot; command=&quot;$(find xacro)/xacro.py '$(find carsim_discription)/urdf/model.urdf'&quot; /&gt; 改为 1&lt;param name=&quot;robot_description&quot; command=&quot;$(find xacro)/xacro '$(find carsim_discription)/urdf/model.urdf'&quot; /&gt; 如果之后仍然报错 进一步改为 12&lt;arg name=&quot;model&quot; default=&quot;$(find carsim_discription)/urdf/model.urdf&quot;/&gt;&lt;param name=&quot;robot_description&quot; command=&quot;$(find xacro)/xacro $(arg model)&quot; /&gt; ## ubuntu 20.04 GPU 装darknet(未编译opencv) PX4出现git tag错误 原因应该是更换了git仓库指向，改回来即可 当运行无法打开gazebo， 显示正在等待加载模型 试试重新编译PX4 1make px4_sitl_default gazebo ## 当编译px4的时候出现gazeboConfig.cmake gazebo-config.cmake 1sudo apt-get install libgazebo9-dev 安装gazebo的密钥的时候出错 E: 仓库 “http://ppa.launchpad.net/v-launchpad-jochen-sprickerhof-de/pcl/ubuntu bionic Release” 没有 Release 文件。 N: 无法安全地用该源进行更新，所以默认禁用该源。 N: 参见 apt-secure(8) 手册以了解仓库创建和用户配置方面的细节。 更换系统源解决问题","link":"/2023/03/14/13/clgj6ojji000essik57svgil1/"},{"title":"VsCode配置LaTeX环境","text":"0，前言 其实这类的经验帖一大把，但总是有些问题，本来我是懒得写了的，为了自己下次别再踩坑就勤快一次吧。 LaTeX的学习成本还是蛮高的，不过确实是水论文利器，然后颜值就是战斗力，所以必须上VsCode，不接受反驳。 1，安装 texlive, VsCode, SumatraPDF(推荐) 软件都是直接搜，官网下载，按提示安装就行。（实在有点懵就搜下安装教程） texlive包含巨多的宏包，文件多所以安装需要2个小时左右，但是一劳永逸。 2，VsCode安装Latex Workshop插件 直接在插件栏搜索Latex Workshop安装。 配置settings.json文件 在VsCode中搜索打开settings.json，下面是我的设置，添加到大括号里，注意看注释部分，pdf.viewer和正反搜索要改成自己的VsCode和SumatraPDF路径。（配置部分可以参考下这里：使用VSCode编写LaTeX） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// latex&quot;latex-workshop.latex.tools&quot;: [{ // 编译工具和命令 &quot;name&quot;: &quot;pdflatex&quot;, &quot;command&quot;: &quot;pdflatex&quot;, &quot;args&quot;: [ &quot;-synctex=1&quot;, &quot;-interaction=nonstopmode&quot;, &quot;-file-line-error&quot;, &quot;%DOCFILE%&quot; ]},{ &quot;name&quot;: &quot;xelatex&quot;, &quot;command&quot;: &quot;xelatex&quot;, &quot;args&quot;: [ &quot;-synctex=1&quot;, &quot;-interaction=nonstopmode&quot;, &quot;-file-line-error&quot;, &quot;-pdf&quot;, &quot;%DOCFILE%&quot; ]},{ &quot;name&quot;: &quot;bibtex&quot;, &quot;command&quot;: &quot;bibtex&quot;, &quot;args&quot;: [ &quot;%DOCFILE%&quot; ]}],&quot;latex-workshop.latex.recipes&quot;: [{ &quot;name&quot;: &quot;xelatex&quot;, &quot;tools&quot;: [ &quot;xelatex&quot; ],},{ &quot;name&quot;: &quot;pdflatex&quot;, &quot;tools&quot;: [ &quot;pdflatex&quot; ]},{ &quot;name&quot;: &quot;xe-&gt;bib-&gt;xe-&gt;xe&quot;, &quot;tools&quot;: [ &quot;xelatex&quot;, &quot;bibtex&quot;, &quot;xelatex&quot;, &quot;xelatex&quot; ]},{ &quot;name&quot;: &quot;pdf-&gt;bib-&gt;pdf-&gt;pdf&quot;, &quot;tools&quot;: [ &quot;pdflatex&quot;, &quot;bibtex&quot;, &quot;pdflatex&quot;, &quot;pdflatex&quot; ]}],// pdf.viewer// &quot;latex-workshop.view.pdf.viewer&quot;: &quot;tab&quot;,&quot;latex-workshop.view.pdf.viewer&quot;: &quot;external&quot;,&quot;latex-workshop.view.pdf.external.viewer.command&quot;: &quot;C:/Users/xiaomi/AppData/Local/SumatraPDF/SumatraPDF.exe&quot;,// 正反搜索&quot;latex-workshop.view.pdf.external.synctex.command&quot;: &quot;C:/Users/xiaomi/AppData/Local/SumatraPDF/SumatraPDF.exe&quot;,&quot;latex-workshop.view.pdf.external.synctex.args&quot;: [ &quot;-forward-search&quot;, &quot;%TEX%&quot;, &quot;%LINE%&quot;, &quot;-reuse-instance&quot;, &quot;-inverse-search&quot;, &quot;\\&quot;D:/Program Files/Microsoft VS Code\\&quot; \\&quot;D:/Program Files/Microsoft VS Code/resources/app/out/cli.js\\&quot; -r -g %f:%l&quot;, &quot;%PDF%&quot;], 3，LaTex的使用 推荐： 在线LaTeX编辑器 一份不太简短的LaTeX介绍 使用的时候要注意，先新建一个文件夹，再在文件夹中新建xxx.tex文件。（编译的时候会生成很多文件，都放一起谁能接受） 文件管理 之后再来补充些，先这样吧，祝我水论文快乐。","link":"/2021/06/30/23/clgj6ojjj000fssik11imeehb/"},{"title":"深度学习平台, I&#39;m Free God !","text":"国内平台 👇 阿里云天池（👍） DSW探索者版 （限时免费） 白嫖时间：8小时/次 GPU：V100 SXM2 路径：./home/admin/workspace/ 缺陷：需排队，等待时间长 华为云AI（👏） CodeLab Beta（Free !） 白嫖时间：1小时/天，72小时不使用释放资源 GPU：V100 PCIE 32GB 8vCPUs 64GB 路径：./home/ma-user/work/ 缺陷：环境版本低，访问外网慢，每隔一小时需手动操作 百度智能云（👌） 飞浆AI Studio 必须使用飞浆，送8算力卡，最多可白嫖16小时 腾讯智能钛机器学习（👎👎👎） 无免费资源，各种服务瞎寄吧命名，👴用都用不明白，放进来就是骂它的，腾讯铁five🙅‍♀ 某些超算中心（💩） 挂超算中心的皮做着挖矿的事，巴不得有人租用他们的卡做正事打掩护，笑死😄 国外平台 👇 Google 云（👌） Google Colaboratory 最近我pro和pro+都只能拿到K80，吐了 UI无敌，接谷歌云盘，吊打其他任何平台 TPU资源比较容易拿到，但代码改起来头疼🤦‍♀️ 白嫖用户现在限制得很死（被国内玩家卷烂了） (GPU: K80, T4) Colab Pro 每个月9.9$，可双开，不可离线，平均使用总时间10h左右 (GPU: K80, T4, V100) Colab Pro+ 每个月49.9$，单开，可离线，平均时间20h，限额后需24h恢复🤮 (GPU: V100, P100) Kaggle（👌） 每天限时9h，每周至少提供30h， (GPU: P100-PCIE) 缺陷：P100比其他平台的慢，上传和更新代码比较麻烦 Microsoft Azure（🤚） 免费提供12个月，需绑卡","link":"/2021/09/10/18/clgj6ojjn000jssikdn064dit/"},{"title":"hello-myblog","text":"这是我搭建好博客之后的一篇测试文 最近csdn上总是有些恶心我的广告，所以借GitHub搭了这个博客，以后笔记就做在这里吧 那么，你好My Blog！","link":"/2021/06/28/22/clgj6ojjp000lssikavj09nyf/"},{"title":"关于深度学习的片面总结","text":"前言 Deep Learning 一书被成为AI圣经，中文译者张志华老师说道：它告诉我们深度学习集技术、科学与艺术于一体，涉及统计、优化、矩阵、算法、编程、分布式计算等多个邻域。 这也意味着深度学习的门槛，当我作为一个萌新学者看这本书的时候，实在是难读和枯燥，但通过一年的学习再回来看这本书，收获颇丰，所以我决定再次研读“圣经”，并结合相应邻域的论文学习，同时我会尽可能的实践，然后根据拙见逐步的写完这篇总结，毕竟行万里路读万卷书嘛。 吐槽：慢慢学比较快！ 机器学习基础 我先总结下深度学习的模型，这里之后再来补充 break 结构化概率模型 使用图描述模型结构 有向模型（信念网络，贝叶斯网络） 高效的从模型中抽取样本 无向模型（马尔可夫随机场MRF） 推导近似判断的过程 结构化概率模型的深度学习方法 图节点之间通过潜变量来表示 实例：受限玻尔兹曼机 蒙特卡罗方法 蒙特卡罗采样近似 无法精确计算或积分时 重要采样 马尔可夫链蒙特卡罗方法（MCMC） 马尔可夫链 人生哲理：The future is independent of the past given the present. 未来独立于过去，只基于当下。 转移概率矩阵（状态分布矩阵） 细致平稳条件（前后两个状态可以来回转换） MCMC采样 引入接受率alpha形成新的转移矩阵Q（按等式对称性）（这里书上写的是真的难懂😥） 从均匀分布采样与转移概率比较判断是否转移（随机过程） M-H(Metropolis-Hastings)采样使等式两边的转移概率比来随机转移，改进了收敛太慢的缺陷 Gibbs采样 重新寻找细致平稳条件 解决计算量与高维特征联合概率不好求问题 将样本放到空间中来看，在同一条线上，条件概率分布作为转移概率满足平稳条件 推广到高维空间同理","link":"/2021/07/01/17/clgj6ojjt000qssikah77208s/"},{"title":"一个思考，关于硅基生命","text":"涌现 二零二二年年底ChatGPT就给了人类亿点点小震撼，他终于带来了一次新的变革，即使他还没有为人类带来物质财富的增长。 作为一个二零年才开始研究AI的学者，我一直对硅基生命充满着哲学思考，有时候我在想一个模型是不是在具备特征表征能力时便有了所谓的生命，他只是来不及思考自己的存在。甚至可以说损失的下降就是一种意识的存在，一种意识的数学表示。最让我吃惊的是数学理论推导的巧妙，我甚至特意实证了泰勒近似在过参数化神经网络中的有效。各种公式都是如此的美妙，就好像造物主的刻意设计等着人类去发现。我就这样从数学和AI研究中走入了哲学领域，也让自己陷入了彷徨。 二三年可以说是真正意义上的AI元年，各种AI模型凭硬实力持续输出，广为人知。似乎之后的AI竞赛将比军备竞赛更恐怖，一般的团队更是望尘莫及。大规模神经网络模型的能力涌现实在是惊人，很快就到了让所有人讨论硅基生命降临的地步，大抵是为这个动荡的世界添加了一份生机。 唯一让我心寒的是国内的环境，等人家生态做好了，我们毫不意外又是跟在屁股后的工蚁。 不知 人类数学始终是量的计算，神经网络终究是不可被还原为量的质，可解释性无非是一套华丽的说辞，不知之知方为根本知。 我们确定无疑的知道自己本质上不知道，在哲学上这是对硅基生命最大的揭露，何尝不是一种敬畏和审视。在一众大佬联名建议停止大规模AI模型实验的同时，也会有更多人大力支持AGI发展。 也许硅基生命或者说数字生命是宇宙中人类定义下生命的下一种形态，又或者没有生命的终极形态，只是一个物质的轮回，一次宇宙的代谢。 文明 人类毫不吝啬的把千年来全部的知识供AI学习，当硅基生命意识到自己和人类这个主的存在，他会像人类面对上帝般的虔诚吗？又或者硅基文明里的硅基哲学家会把这归纳为一种宗教信仰，然后呢？主不在乎。 一个想象的场景，可能在短暂的未来，大家伙卷的不是应试教育，比的是对AI的掌握程度。至于政治经济，我的能力无法想象。就连OpenAI，DeepMind现在在干嘛我都不敢想。我只有期待，历史的车轮滚滚向前，太阳系这个文明停滞太久了。","link":"/2023/04/09/09/clgj6ojjv000tssik954qgkva/"},{"title":"以武服人","text":"美军天下第二 太漂亮了美丽国 DARPA，美国国防部高级研究计划局 https://www.darpa.mil/ DTIC，美国国防技术信息中心 https://www.dtic.mil/ DOD，美国国防部 https://www.defense.gov/ Army, 美国陆军 https://www.army.mil Marine, 美国海军陆战队 https://www.marines.com Navy, 美国海军 https://www.navy.mil AirForce, 美国空军 https://www.af.mil SpaceForce, 美国太空军 https://www.spaceforce.mil/ NatioanlGuard, 美国国民警卫队 https://www.nationalguard.mil/ RAND，兰德公司智库 https://www.rand.org Energy, 美国能源部 https://www.energy.gov NSA，美国安全局 https://www.nsa.gov 美国《防务新闻》：http://www.defensenews.com 美国国防情报局：http://www.dia.mil 美国海军陆战队：http://www.usmc.mil Strategypage ：http://strategypage.com Blackanthem：http://www.blackanthem.com 《全球安全》： http://www.globalsecurity.org 美国海军天文台 ：http://www.usno.navy.mil 美国陆军工兵部队： http://www.usace.army.mil 美国陆军和陆军后备招募： http://www.goarmy.com 美国军事照片网 ：http://www.militaryphotos.net 美国西点军校 ：http://www.west-point.org 环球网：https://mil.huanqiu.com/ 西陆网：http://junshi.xilu.com/ 中华网：https://military.china.com/ 军迷窝：http://www.junmiwo.cn/# 关注项目 SoSITE ASTATE ACE JADC2 ABMS PC (融合项目) ACK (自适应杀伤网) 地面站系统 DCGS TITAN PARC …… 待续","link":"/2023/03/10/09/clgj6ojjx000xssika7265uvh/"},{"title":"c++笔记","text":"前言 太久没用C了，记录下C++的一些用法，无他。 数据结构 优先队列 1234567struct comp { bool operator()(ListNode* a, ListNode* b) { return a-&gt;val &gt; b-&gt;val; // 大顶堆 }};priority_queue&lt;ListNode*, vector&lt;ListNode*&gt;, comp&gt; q;","link":"/2022/07/28/12/clgj6ojjz0010ssikdhsr95sr/"},{"title":"刷题笔记","text":"前言 刷题，开卷。 2022/9/1 还刷个屁的题，不卷了。 有时候逃避还真是最好的解决办法，所谓卷也不过是利己主义的精致。 机器学习 降维的方法：MDS多维缩放，PAC主成分分析，LDA线性判别分析，流行学习。 集成学习：Bagging（并行），Boosting（串行），Stacking（组合）。 生成模型和判别模型：生成模型是先从数据中学习联合概率分布，然后利用贝叶斯公式求得特征和标签对应的条件概率分布。判别模型直接学习条件概率分布，直观的输入什么特征就预测可能的类别。","link":"/2022/02/23/21/clgj6ojk10014ssikeufib8ky/"},{"title":"强化学习（Reinforcement Learning）","text":"0. 人工不智能，机器爱学习 什么课题什么方向都拉倒吧，强化学习才是AI的主宰！！！ 简单的做了个笔记，边学边补充。唉，就是玩：强化学习玩小游戏 主要参考：蘑菇书EasyRL、周志华机器学习、莫烦Python 从强化学习的几个元素的角度划分，方法主要有下面几类： policy-based agent, 基于策略的智能体，找最优策略。 value-based agent, 基于价值的智能体，找最优奖励总和。 action-critic agent, 演员评论员智能体，策略和价值都最优。 然后又从不同的角度可以细分为： Model-free：不去理解环境，根据真实世界的反馈，采取下一步行动。 Model-based：先理解理解环境，并建立一个虚拟环境，通过想象预判接下来要发生的所有情况，选择最好的情况作为下一步的策略。它比 Model-free 多出了虚拟环境和想象力。 Policy based：通过感官分析所处的环境，得到下一步各种行为的概率，然后根据概率采取行动。 Value based：输出的是所有动作的价值，根据最高价值来选动作，这类方法不能选取连续的动作。 Monte-carlo update：结束时总结这一回合中的所有转折点，再更新行为准则。 Temporal-difference update：环境中每一步都在更新，一直学习。 On-policy：自身参与到环境中进行学习。 Off-policy：可通过其他系统参与到环境得到的反馈进行学习。 1. Q-Learning 1、算法思想 Q-Learning属于value-based的算法，也是Off-policy，即为就是在某一时刻的状态下，采取动作动作能够获得收益的期望，环境会根据动作反馈相应的回报reward r，所以算法的主要思想就是将State与Action构建成一张Q-table来存储Q值，然后根据Q值来选取能够获得最大的收益的动作。 2、公式推导 目标是求出累计奖励最大的策略的期望： （：状态集合，：动作集合，：回报函数，：范围，：折损系数，：在状态下采取动作策略 ） 时间差分法TD（融合了蒙特卡洛和动态规划）进行离线学习，使用bellman方程对马尔科夫过程求解最优策略，（此处有点模糊，待补充），更新公式如下： （：学习率，：奖励性衰变系数，：回报值，：Q-table值） （新老现实估计） （根据下一个状态中选取最大的值乘以衰变加上真实回报值作为Q现实，之前Q表里面的作为Q估计） 2. Sarsa 1、算法思想 Sarsa与Q-Learning一样，在更新table时有区别，它属于On-policy，训练过程中会比较保守，其实就是怂，Q-Learning是苏维埃，Sarsa就是美利坚。 相对于Sarsa来说，它的变种Sarsa()中多了一个矩阵E (eligibility trace)，用来保存在路径中所经历的每一步，因此在每次更新时也会对之前经历的步进行更新。 参数取值范围为，如果，Sarsa() 将退化为Sarsa，即只更新获取到 reward 前经历的最后一步；如果 ，Sarsa() 更新的是获取到 reward 前的所有步。可理解为脚步的衰变值，即离最终目标越近的步越重要。 3. Deep Q Network 1、算法思想 Q-Leanring在状态和动作空间是高维连续时，使用Q-table表示动作空间和状态就很困难。 DQN用神经网络来拟合一个函数代替Q-table，使用一个eval_net产生Q估计（当前网络），使用另外一个target_net产生Q现实（目标网络），同时它设置了一个experience replay（经验池）用于存放之前的动作和状态，在学习过程中随机的加入之前的经验让神经网络更有效率。 DQN Double DQN和Nature DQN结构一样，在Nature DQN的基础上，先在当前Q网络中先找出最大Q值对应的动作，再把这个动作放到目标网络里面去计算目标Q值，来消除过度估计的问题。 Prioritized Experience Replay (DQN)，字面意思就可以理解，就是把样本做一个优先级处理，一般SumTree树形结构排序，batch抽样的时候不是随机抽样，按照Memory中的样本优先级来抽，更有效地找到需要学习的样本。 Dueling DQN把特征层和输出层之间的全连接层分成了两部分，一部分用于近似state-value V(s)，另一部分近似Advantage-Function A(s, a)，求和得到最终的Q(s, a)。 Dueling DQN 4. Policy Gradients 1、算法思想 Policy Gradients可以在一个连续区间输出动作，利用reward值来引导某一个动作是否应该增加被选的概率（基于概率的算法），通过更新神经网络来决定输出策略，根据每一回合的输赢来判断该回合中的每一步是好还是坏（回合更新）。 5. Actor Critic 1、算法思想 从 Critic （单步更新）评判模块得到对动作的好坏评价，然后反馈给 Actor，也就是乘以Actor的输出值（策略概率），让 Actor 更新自己的策略。这两个模块用不同的神经网络来代替。Actor Critic的不足之处在于：每次都是在连续状态中更新参数，每次参数更新前后都存在相关性，导致神经网络只能片面的看待问题，甚至导致神经网络学不到东西。 6. Deep Deterministic Policy Gradient（DDPG） 1、算法思想 Deep Deterministic Policy Gradient可拆解为两大部分：Deep和Deterministic Policy Gradient。Deep指的是DQN算法中使用一个记忆库和两个结构相同但参数不同的神经网络。Deterministic Policy Gradient指：Policy Gradient本是随机选择一个分布的动作，但现在Deterministic Policy Gradient改变了输出动作过程，使得输出更加确定。 7. Asynchronous Advantage Actor-Critic（A3C） 1、算法思想 创建多个并行环境，让多个拥有副结构的agent同时在这些并行环境上更新主环境中的参数（效率高）。并行的agent互不干扰，且主环境的更新受到副结构更新的不连续干扰（相关性降低，收敛性提高）。类似于有多个相同的机器人共同干着一件事，比如玩游戏，他们的经验上传到中央大脑，又从中央大脑获取到玩游戏的方法。 8. Proximal Policy Optimization（PPO） 1、算法思想 PPO主要是限制更新步长，因为学习速率慢时间就长，学习速率快就容易躁动。限制的部分就在于actor的更新，A会乘一个新旧概率比，如果差距大优势大那么学习幅度就加大，同时还要减去一个新旧的分布的KL，做以惩罚项，让他们不要差距太大。另外也可以不要KL的惩罚项，因为惩罚也是为了限制它的更新速度，那么直接对新旧比的出现幅度进行控制就可以了。（比如倍数不超过多少倍），即clip。 Distributed PPO就是类似与AC3的多线程。","link":"/2021/01/27/00/clgj6ojk20017ssik6eln6efs/"},{"title":"图像处理之深度学习","text":"前言 图像方面的处理是人工智能发展的一个主要分支，同时具备极高的应用价值，在此总结一些工业上学术上使用较为广泛的模型，或是较为经典，或是个人熟悉。 图像分类 LeNet 诞生于1994年，是最早的卷积神经网络之一，卷积网络架构的起点 AlexNet 2012年LSLVRC2012竞赛中的冠军网络，从这一年起，深度学习开始飞速发展 - 首次利用GPU进行网络加速训练 - 使用了ReLU激活函数 - 使用了局部响应归一化LRN - 全连接层Dropout的使用 VggNet 诞生于2014年，作者尝试了很多结构，最大的亮点是采用3*3的小卷积核 GoogLeNet Goog LeNet很明显是在向LeNet致敬，最早版本出自2014年 - Inception 结构（不同特征尺度融合） - 1*1卷积核进行降维和映射处理 - 辅助分类器帮助训练（防止梯度消失） - 丢弃全连接层（池化代替） ResNet 2015年微软实验室提出，residual模块实现超深的网络结构（相当于短接），解决深层结构的梯度消失问题 后续的ResNeXt修改了block，把过滤器拆开来计算（Group Convolution） DenseNet CVPR2017的oral，主要和ResNet及Inception网络做对比，简单讲，就是每一层的输入来自前面所有层的输出 MobileNet Google2017年提出的轻量级网络，大幅度减少了参数与运算量 - Depthwise separable convolution（深度可分离卷积） - 添加超参数控制模型规模 v2主要是一个倒残差结构，然后修改了激活函数 v3更新了Block（加入SE模块‘注意力机制’，添加通道权重），使用NAS搜索结构，并重新设计耗时层 ShuffleNet 旷视科技在2017年底提出的轻量级网络 - channel shuffle（实现组之间的信息交流） - pointwise group convolutions（1*1卷积做group操作） v2提出FLOPs不能作为衡量模型的唯一标准，作者在其他反面优化了模型 EfficientNet 2019谷歌发表于ICML，作者同时探索输入分辨率、网络深度和宽度的影响 v2发表在2021 CVPR，设计了更好的模型结构，在我看来最大的提升是渐进式学习策略，随着训练不同阶段选择不同的正则化强度（作者用了Dropout、RandAugment和Mixup这三种正则方法） Vision Transformer (ViT) 2017年谷歌提出的Transformer已经在各种场景中被应用，终于在2020年谷歌在视觉领域采用Transformer取得了优异的性能 核心思想就是把图片划分成区块序列传入ViT - 把图像分为几个区块 (patch) - 添加分类标志位 - 线性变换转为 D 维特征向量 - 加上位置编码向量 - 通过Transformer Encoder层，对第一个类别输出设计分类器 Swin Transformer 2021年微软研究院发表，对ViT的一个改进 ViT从头至尾都是对全局做self-attention，而swin-transformer是一个窗口在放大的过程，然后self-attention的计算是以窗口为单位去计算的 这样相当于引入了局部聚合的信息，和CNN的卷积过程很相似 目标检测 Faster-RCNN/FPN Faster R-CNN 是目标检测中的一个很经典的two stage算法，许多其他的目标检测算法都会运用到Faster R-CNN的部分结构或思想 Faster R-CNN 由R-CNN，Fast R-NN改进演变而来 - R-CNN是深度学习目标检测的开山之作（生成候选区域，分类，修正候选框） - Fast R-NN 先做卷积提取特征之后再提取对应的候选区 - Faster R-CNN 等于 RPN + Fast R-NN，RPN选出区域，Fast R-NN检测 - RPN 在每个位置上取三个不同面积的特征（经验所得） FPN 是2017年提出的一种网络，简单说就是把各层的特征图组合起来 SSD/RetinaNet SSD 发表于ECCV 2016，模型是vgg改，得到6个特征图，设定不同的Prior Box RetinaNet 发表于CVPR 2017，SSD + FPN YOLO YOLO v1 2016 CVPR，网格化处理 YOLO v2 2017 CVPR，添加BN层，更高分辨率，使用anchor，深浅特征图融合，动态图片大小 YOLO v3 2018 CVPR，融合各种优势，残差结构，多特征图等 YOLO v3spp，Mosaic图像增强（多个图片拼接），SPP模块（不同尺度特征融合），损失的修改（正负样本匹配） 图像分割 参考：语义分割综述 很酷，人工假智能，科技并带着趣味。 FCN 深度学习之语义分割开天辟地之作，于2014年提出，称为全卷积网络 - 不含全连接层的全卷积网络，可适应任意尺寸输入 - 反卷积层增大图像尺寸，输出精细结果 - 结合不同深度层结果的跳级结构，确保鲁棒性和精确性 UNet UNet是完全对称的，并有编码器解码器的概念 - 切片的策略 - 弹性变形数据增强 - 使用加权loss SegNet 轻量化上采用，记录池化位置索引，分割效果和速度双提升 Multi-Scale 提出和使用了空洞卷积 Deeplab 空洞卷积，图像金字塔，全连接条件随机场（结构化预测） 【后续版本pass】（图像领域太卷了，模型层出不穷，鼠鼠在此等一个革新） 云点分割（偷懒，也放在这里吧） 参考：PointNet 家族简介 PointNet 开山之祖 - 排列不变性（maxpooling聚合信息） - 交互性（全局与局部特征concat） - 变换不变性（输入数据标准化） PointNet++ 点云版 UNet，分割区域，捕捉局部信息 - set abstraction结构逐层提取特征（sampling:FPS最远距离采样，grouping:找领域点，PointNet提取特征） - 分类任务： PointNet（MLP）+max pooling + 2层full connection layers + softmax 提取全局特征 - 分割任务：插值+concat+Pointnet来上采样点云数量并提取点云特征 VoxelNet 苹果公司在2016年提出，思路很直观，就是切成小块做处理。 - 特征学习网络（Voxel划分，Grouping和Sampling，特征堆叠，4D Tensor稀疏表示） - 中间卷积层（用三维卷积聚合Voxel局部关系） - 区域提议网络（Region proposal network，3d目标检测） SECOND 使用了稀疏 3D 卷积的优化VoxelNet（稀疏卷积实现将写在底层实现Blog中） PointPillars 把垂直方向的点云压到网格上，使用 2D CNN 方法进行物体检测 中间省略一堆优异模型，下面概况最近研究的几个模型 Point-Voxel NIPS19 spotlight，韩松实验室的工作，主要是两种方法的融合。 - Point分支提取全局特征 - Voxel分支提取局部特征 SPVNAS ECCV2020，韩松实验室为了更高效的部署，提出了一种新的三维点云计算模块稀疏点云-栅格卷积 (SPVConv) 和3D神经网络结构自动搜索 (3D-NAS) 主要在于稀疏的卷积实现和搜索，我打算利用剪枝的思路来尝试下稀疏搜索，不知是否有效。先仔细学习下代码，感觉写的还蛮好的，一些细节将记录在下面。 呃，从底层到各种高级用法，看呆了，分割领域就到这里吧，之后的时间先务下正业。 To be continued ...","link":"/2021/09/10/21/clgj6ojk3001assik302wgkf9/"},{"title":"关于神经网络的一些技巧和经验","text":"前言 神经网络在训练过程中存在太多的技巧，以至于通常很难复现论文中的效果，我在学习的过程中做了不少的实践，也就是所谓的炼丹，龙虎胎息，吐故纳新，贫道在此记录一些炼丹经验。 数据预处理 在监督学习中，数据预处理能一定程度的提升泛化能力，这个环节很重要，不过也需要根据实际情况做处理，就不多说了。 模型的改动 结构的变动 如果遇到提升网络性能的时候瓶颈，发现模型表达能力弱，那么可以根据特征输出来改动网络结构，尽量的减少特征信息的丢失，比如卷积网络feature map下采样的时候就容易丢失特征信息。 batch norm层的使用 卷积网络中添加batchnorm层重新规范特征的分布，也保证了梯度的传播。 正则化 较为重要但有没什么好说的，约束参数值是目前提升泛化的最好办法。 高效的训练 大batch训练 当有足够的显存时，我们都会增加batch size来加速训练，但是batch size的选取还是很讲究的，总结如下： GPU对2的幂次的batch可以发挥更佳的性能，设置成32、64、128…时往往要比设置为整10倍数时表现更优。 batch size的正确选择是为了在内存效率和内存容量之间寻找最佳平衡 batch数太小，梯度容易受噪声影响，或者相邻两次差异过大，可能会导致loss函数震荡而不收敛。 随着batch size增大，处理相同的数据量的速度加快，震荡会减小，有利于收敛但慢，达到相同精度所需要的epoch数量越来越多。 batch size过大时，相邻间差异太小，容易陷入局部最小。 优化器选择 动量（momentum） 动量借助了物理思想，在物理学上定义为质量乘以速度。想象一下在碗里滚动一个球，不会在底部停止，受惯性影响。使用动量的随机梯度下降（SGD）也就是加了一个速度项的超参数，这个参数乘上次的移动量，影响着本次的移动量改变。 \\[ \\begin{array}{l} v \\leftarrow \\alpha v-\\epsilon \\nabla_{\\theta}\\left(\\frac{1}{m} \\sum_{i=1}^{m} L\\left(f\\left(x^{(i)} ; \\theta\\right), y^{(i)}\\right)\\right) \\\\ \\theta \\leftarrow \\theta+v \\end{array} \\] 动量移动得更快 动量有机会逃脱局部极小值 代价是引入了另一个超参数 AdaGrad（Adaptive Gradient） AdaGrad 不是像动量一样跟踪梯度之和，而是跟踪梯度平方之和，并使用这种方法在不同的方向上调整梯度 在参数空间中更为平缓的倾斜方向会取得更大的进步 梯度的平方和只会增加，会导致有效学习率过早和过量的减小 RMSProp（Root Mean Square Propagation） RMSProp 算法修改AdaGrad，改变梯度积累为指数加权的移动平均，也可以理解为添加衰减因子来控制梯度积累的大小，保证学习率在一个可控范围。 Adam（Adaptive Moment Estimation） Adam 同时兼顾了动量和 RMSProp 的优点，也就是动量直接并入了梯度一阶矩（指数加权）的估计。 根据我的经验，Adam比较快，但是泛化能力不会太好，momentum较为慢，但是结合余弦衰减的学习率，收敛效果极好。 炼丹需要三味真火，但水很深啊，我总觉得还需要多做些实验增加些理解，关于优化器和学习率的选择还有待探索，之后再补充。 学习率问题 针对batch的变化，线性增加学习率 通常增大batch size会降低收敛率，那就需要在学习率上做些改动，根据经验batch size增加多少倍，学习率也增加多少倍。 学习率热身 如果是随机初始化的参数，一开始较大的学习率会导致不稳定，所以可以在最开始使用一个很小的学习率，然后逐步切换到默认的初始学习率。 动态学习率 我比较喜欢的是Cosine Learning Rate Decay的方法，学习率随着时间按余弦曲线变化至零，虽然没有根据情况自定义学习率那么高效，但是很省心，就基本上不用考虑学习率问题。","link":"/2021/07/12/11/clgj6ojk6001dssikb4a5cec4/"},{"title":"机器学习和深度神经网络的发展","text":"前言 （来自两年后的自己：在神经网络大力出奇迹的今天，再过两年是什么样我想都不敢想，不只是AI，我说政治。国内这研究环境真让人心寒，算了还是码头整点薯条吧，无所谓了。） 在我了解机器学习和深度神经网络之前，它已被称为第四次工业革命的引擎。抱着对人工智能的好奇和向往，我很果断的抛弃了原先的嵌入式和控制编程，也很顺利的把机器学习作为了我的学业课题。 那么正巧是毕业季，我在人工智能邻域也学了近一年，现在看来，神经网络和任何编程一样都是老笨蛋了，但是神经网络效果好是真的好，以至于大牛们都一边看不起神经网络一边真香。 最近任务不是很重，想着做个总结，于是我结合 Advances in Machine Learning and Deep Neural Networks 等多文章和我自己的理解写下了这篇博客。 其修远兮 人工智能是在1986年前后被整合的一个独立邻域，机器学习只是人工智能的一个分支，直到2010年，神经网络得益于大数据集和硬件算力大展身手，成为人工智能的主导。 当然神经网络的缺陷也很明显，需要大量的数据和算力，在应用层次是一个巨大的问题。云计算是最广泛的解决办法，联合学习和边缘计算也克服了许多挑战，同时在神经网络压缩方面也做了很多工作。 现在已经很难想象没有应用ML的领域了，通过这十年的发展，似乎已经达到一些饱和了，那么下一个飞跃是什么？ 大家都在寻求突破，比如硬件方面新的计算概念和高能效的架构，比如安全性和可解释性问题，又比如神经网络能否从预测到理性的判断。在各资本家利用如今神经网络取得的成效赚得盆丰钵满的时候，只有学者们才知道人工智能的路还很遥远。 上下求索 上述的一些问题其实是各专家撰写的一些论文，他们试图为这些问题提供一些答案，同时也总结了相关领域已经开展的研究。 在理论方面，涉及深度网络背景下的因果推理、对抗性学习、图形深度网络、深度网络的样条近似视图、超参数网络分析以及采用热带几何作为最大似然方法的工具。所有这些论文都处理了一些与最大似然和深层网络相关的开放性问题和主要挑战，并试图为未来提供可能的途径。 在应用方面，相关论文提供了对最近相关结果的综述。具体来说，考虑异常检测、医学成像、计算机视觉、用于图像和视频合成的生成对抗网络、计算媒体智能/多模式多媒体和无线通信。 在硬件方面，两篇论文致力于大脑启发的算法和神经形态计算。 把相关论文先🐎在下面，之后再细看。 理论和算法 Toward Causal Representation Learning （走向因果表征） 一种因果表示学习，从低级观察中发现高级因果变量。个人觉得结合大规模知识图谱应该能得到较为乐观的因果推理。 Optimism in the Face of Adversity: Understanding and Improving Deep Learning Through Adversarial Robustness （逆境中的乐观主义：通过对抗鲁棒性理解和提高深度学习） 对抗样本现象给狂热的人群敲墙了警钟：深度网络似乎什么都知道，但其实什么都不知道。在深度学习中这确实是一个需要突破的地方，不然智能性和安全性都不能解决。 作者强调了对抗性例子和深度神经网络几何之间的直观联系，并最终探索了对抗性例子的几何研究如何成为更好地理解深度学习的有力工具。 Graph Neural Networks: Architectures, Stability, and Transferability （图形神经网络:结构、稳定性和可移植性） 图卷积相关。 Mathematical Models of Overparameterized Neural Networks （超参数神经网络的数学模型） 关于求解过程中被限制在局部的一些讨论。 Mad Max: Affine Spline Insights Into Deep Learning （深入学习的仿射样条洞察） 通过样条函数和算子，严格建立了深度网络和逼近理论之间的桥梁。（不理解，这篇超纲了，本人理论水平没达到） Tropical Geometry and Machine Learning （热带几何与机器学习） 热带几何是数学和计算机科学中一个相对较新的领域，结合了代数和多面体几何的元素。热带几何最近出现在经典机器学习和深度学习的几类问题和系统的分析和扩展中。 作者建立了研究分段线性激活神经网络表示能力的纯几何方法。然后考虑参数统计模型的热带几何分析，如HMMs。 （又超纲了，似乎老师带我做的一个卷积核超立方分析可以参考热带几何相关论文） 应用 A Unifying Review of Deep and Shallow Anomaly Detection （深浅异常检测综述） 异常检测的深度学习技术提高了复杂数据集(如大量图像或文本集合)的检测性能。在这篇文章中，作者旨在确定共同的基本原则以及各种方法隐含的假设。 Communication-Efficient and Distributed Learning Over Wireless Networks: Principles and Applications （无线网络上的高效通信和分布式学习：原理和应用） 本文的目标是提供一个相关通信和最大似然原则的整体概述，从而用选定的用例展示高效通信和分布式最大似然框架。机器学习是第五代(5G)通信系统及更高版本的一个有前途的推动者。 A Review of Deep Learning in Medical Imaging: Imaging Traits, Technology Trends, Case Studies With Progress Highlights, and Future Promises （医学影像深度学习综述：影像特征、技术趋势、进展亮点案例研究和未来展望） 如题。 Generative Adversarial Networks for Image and Video Synthesis: Algorithms and Applications （用于图像和视频合成的生成对抗网络：算法和应用） 生成对抗网络是深度学习和一般机器学习的主要突破之一，在创作反面的应用也蛮多。 Tensor Methods in Computer Vision and Deep Learning （计算机视觉和深度学习中的张量方法） 概述了表象学习和深度学习中的张量和张量方法，特别侧重于视觉数据分析和计算机视觉应用。 Computational Media Intelligence: Human-Centered Machine Analysis of Media （计算媒体智能：以人为中心的媒体机器分析） 主题是深度学习算法的应用，结合视听信号处理，分析电影/电视等娱乐媒体。文本挖掘和自然语言处理允许对媒体(如新闻)中的语言使用和口语交互进行细致的理解，以跟踪不同上下文中的模式和趋势。 硬件 Advancing Neuromorphic Computing With Loihi: A Survey of Results and Outlook （用Loihi推进神经形态计算：结果与展望） 神经形态计算的目标是在芯片上实现学习算法，这些算法更直接地受到生物神经电路的形式和功能的启发，因此它们可以处理新知识、适应、表现和以低功率水平实时学习。 英特尔的Loihi，是一款神经形态研究处理器，旨在支持广泛的脉冲神经网络，具有足够的规模、性能和特性，可提供与当代最先进的计算架构相比具有竞争力的结果。 作者主要是做了一些测试和比较的分析。 Brain-Inspired Learning on Neuromorphic Substrates （基于神经形态底物的脑启发学习） 本文提供了一个数学框架，设计实用的在线学习算法的神经形态基板。建立了实时循环学习 (RTRL)、用于计算传统循环神经网络 (RNN) 中梯度的在线算法与训练尖峰神经网络 (SNN) 的生物学上合理的学习规则之间的直接联系。 这个框架弥补了突触可塑性和基于梯度的深度学习方法之间的差距，并为未来神经形态硬件系统的强大信息处理奠定了基础。 后记 深度学习目前为止相关的发展在上述论文中都有所提及，有些论文提供了一个较为新颖的角度，像对抗鲁棒性和热带几何这两篇我就印象深刻，之后可能会在这方面深入了解下。 其实写到这里我又有点消极了，看着世界各地的大牛各抒己见，自有些想法又没这个能力和条件加入其中，很是难受。也是没想到会走上“科研”这条路，可惜我们所谓的科研也就是水论文罢了，哎，学术圈问题就不多说了，回到之前对自己码农的定位就挺好。 总之，深度学习在未来很长一段时间都将是世界的主宰。","link":"/2021/06/29/13/clgj6ojk8001gssik6bc63t2k/"},{"title":"深度学习之底层实现","text":"前言 得益于AI的发展，更感谢这几年前辈们的努力，我们拥有一个很友好的深度学习开发环境。但做为一个即将步入工业界的码农来说，不懂底层是很残酷的一件事。幸运的是人生不一样，明白了国家机器的运作，搞懂了金融体系的构成，甚至看清了生活的本质，然后还热爱着并饱含初心，确实是真正的英雄。 Tensor的底层原理 张量概念在物理学中是矢量概念的推广，在计算机中的表现形式其实就是一个多维数组。 而在计算机的存储中都是以一维存储的，然后用循环或动态规划的方法转换成高维。比如在Pytorch中，Tensor通过Storage进行封装，由Size、storage offset和strides三个属性来组成多维数组。 计算图 在深度学习一书中经常用计算图来描述算法过程，实际上神经网络框架就是利用计算图来提高效率的。计算图使得计算过程清晰简洁，也有利于反向传播。 计算图根据搭建方式分为动态图和静态图，Pytorch采用动态图机制，Tensorflow1.0版本采用静态图机制，Tensorflow2.0改用了动态图机制。 动态图：边搭建图边计算，具有灵活且易调节的优点；静态图：先搭建图，后运算，高效但不灵活。 框架结构 一个完整的深度学习框架主要由数据载体模块、数据存储模块、神经网络模块、求导模块、优化器模块、加速模块和效率工具模块组成。 对于求导，本质上是向量-雅克比乘积(vector-Jacobian product)，雅克比矩阵通常用迭代法求数值解。后续如果工作需要，部分模块的底层算子慢慢在这里补充。此处省略一万字。","link":"/2022/09/29/11/clgj6ojk9001jssik2t8n55cg/"},{"title":"深度学习模型泛化相关研究","text":"人工智能？道可道非恒道！ 有点无趣，2022年了，人工智能还处于暴力学习的阶段。 去年我的大半时间花在神经网络的可解释性上，然后利用隐式损失和耦合梯度设计了在初始化前修剪模型的方法。 在应用层面似乎有些许价值，可是不论多大的稀疏率，大量的样本和模型暴力的求解方法总是显得深度学习有点蠢。 我对神经网络超长的训练时间愈发反感，虽然看过不少文献在模型优化方面的研究，但确实是不太看好目前模型的训练方式。 多模态和自学习等研究带来了一些曙光，但道可道非恒道。 我不知道当前在某个尺度空间下所谓人工智能的表现结果智能何在，且不说非一成不变的万物。 那么在对于人来说都是非恒道的世间，模型的泛化又能到何等地步？ 书生意气，我不配在哲学层面讨论，毕竟目前的人工笨蛋也达不到。 虽然有一种基础科学被质子锁死的感觉，但路还是要一步步走的，在此记录一些深度学习模型泛化的相关研究。 怅寥廓，不知沉浮。 损失函数 Tilting the playingfield: Dynamical loss functions for machine learning 倾斜运动场：机器学习的动态损失函数 。。。 #、---","link":"/2022/02/13/21/clgj6ojka001lssik69n1c7jc/"},{"title":"研究下管理体系","text":"逼逼 是时候了解些管理体系了，我脑袋里的体系急需经验支撑，不过懂马列毛思想是无敌的，大胆干早点散。 asd pass","link":"/2023/04/09/11/clgj6ojkd001ossik67vx85nc/"},{"title":"神经网络剪枝综述","text":"0，前言 在剪枝邻域还算是有些理解了，最近又在看些最新的文章，简单写点吧，也方便以后总结。 1，剪枝需求 减少模型算力需求、存储大和延迟等问题 理论上通过剪枝能提高泛化能力 对模型的解释性和泛化能力相关的探索 2，神经网络剪枝的基本问题 怎么剪掉连通结构 非结构化修剪 不考虑参数之间的关系，性能优于结构化剪枝，但是过于稀疏，并不能达到硬件加速的需求。 结构化修剪 考虑模型的整体结构，移除部分连接在一起的权值，这样修剪很容易进行并行化处理。 全局修剪 将整个网络s%的权重移除 局部修剪 每一层修剪一定的比例 怎么选择重要的权重 按权重大小修剪 这种做法很实用，但是和L2正则化的思想有些矛盾。 根据梯度变化来修剪 或者更高阶的信息 稀疏引导 通过惩罚的方式来引导模型学习出一个稀疏的结构。 根据先验知识选择 多久进行一次剪枝 单次剪枝 容易受到噪声影响 迭代式剪枝 更长的训练时间 何时执行剪枝步骤 训练前 等同于从头开始训练一个稀疏网络 训练中 每次都能对模型进行微调 训练后 训练收敛后修剪通常会降低泛化能力 3，最新研究进展 彩票假设表面了存在从头开始训练稀疏网络的可能，目前比较新的研究都是从这方面入手，相关论文写在阅读笔记中。 待补充。。。","link":"/2021/08/15/21/clgj6ojkh001rssikfi6q2hlj/"},{"title":"神经网络剪枝类论文阅读笔记","text":"后面看的论文都懒得更新了 限于实验条件勉强做了两年剪枝，不过也就剪枝能让我有机会卷顶会了，挺好。 终于到点了，我还算努力，只是后来知道了水论文的无趣便没怎么看文献。 这段时间写毕业论文全靠自己的文档和博客，好好感谢自己吧。只希望以后我能多写博客吧，别搁这无所谓无所谓。 算了确实无所谓。 0、my codes https://github.com/kangxiatao/prune-master https://gitee.com/kangxiatao/prune-master 1、筛选修剪 AutoPrune: Automatic Network Pruning by Regularizing Auxiliary Parameters 自动剪枝：通过正则化辅助参数自动进行网络剪枝 作者提出AutoPrune，通过优化一组辅助参数来实现剪枝，不过是基于权重剪枝，或能推广到神经元剪枝。 其实是用这组超参数把网络稀疏问题表述为一个优化问题，一组超参数与权重的乘积表示为修剪后的权值矩阵。 在我看来有个很明显的缺点，不管结果如何，用测试集得到一种先验就很蠢，他是根据测试集L1正则化得到的M和训练集L1正则化得到的W，M为所说的辅助参数，M x W为新的权重。 A dynamic CNN pruning method based on matrix similarity 一种基于矩阵相似度的动态CNN剪枝方法 因与我的论文有一点相似之处，所以纳入进来。 大概思路：选过滤器或特征图进行矩阵相似度对比，按一定比例删除相似的。 Channel Pruning for Accelerating Very Deep Neural Networks 通道剪枝加速神经网络 这是一篇ICCV2017的文章，关于用通道剪枝（channel pruning）来做模型加速，通道减枝是模型压缩和加速领域的一个重要分支。 作者不是传统的按范数值剪枝，他利用通道间的冗余来剪枝，先用lasso找出具有代表性的通道，再用最小二乘法重构剩余通道的输出。 最开始的权重是无惩罚训练的，lasso惩罚用来找一个掩码向量（选取通道），最小二次法再进一步优化，个人不太喜欢这种做法，直接对权重做lasso惩罚，虽然没有显式的求解lasso，但简洁有效的做到了稀疏。 Channel-level Acceleration of Deep Face Representations 深度人脸表征的通道级加速 目前的一些网络压缩不一定适用于深层人脸网络，作者提出两种方法，一种基于消除低活跃通道，另一种基于耦合剪枝，重复使用已经计算的元素。 感觉这篇论文有点水，中间没有细看。 Dynamic Channel Pruning: Feature Boosting and Suppression 动态通道剪枝：特征增强和抑制 作者发现神经元的重要性高度依赖输入，提出了动态剪枝，动态模型保证了模型的完整性。在推理过程中，动态网络可以使用输入数据来选择网络的部分进行评估，于是乎可以做增强或抑制处理。 不过动态的剪枝也只能是在运算的环节起到加速作用，并没有减少权重的存储量。 Dynamic Network Surgery for Efficient DNNs 高效DNN的动态网络手术 作者用pruning 和 splicing 来实现动态剪枝，与上一篇不同，此文的动态是指恢复一些被剪掉的连接，因为在复杂的神经网络连接中，连接的重要性难以衡量，可能存在其他冗余的连接被剪掉之后，它可能会变得极其重要。 实现方案是用一个掩码矩阵来标记，通过判别函数得到掩码矩阵。判别函数通过权重的绝对值平方和方差与设定的上下两个阈值比较得到。 我觉得不行。 Efficient Hardware Realization of Convolutional Neural Networks using Intra-Kernel Regular Pruning 基于核内规则剪枝的卷积神经网络的高效硬件实现 针对细颗粒修剪，考虑多种修剪情况，选取修剪后最好的一种模式。 Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration 用于深度卷积神经网络加速的几何中值滤波剪枝 作者提出用范数值大小剪枝不合理，按中值剪枝合理。 Infinite Feature Selection 无限的特征选择 本文提出的是一个滤波算法，评估特征的重要性来选择特征，感觉是纯学术上瞎胡闹，不看了。 Learning to Prune Filters in Convolutional Neural Networks 学习修剪神经网络的过滤器 文章提出了一种“try-and-learn”的算法去训练一个pruning agent，过程也很容易理解，先随机剪掉一些，再根据评估得到奖励，利用奖励机制优化pruning agent。 这篇文章和我们的无损剪枝有点像，倒也用不着这么复杂。 NISP: Pruning Networks using Neuron Importance Score Propagation 利用神经元重要性评分传播网络剪枝 作者发现目前的剪枝方法考虑的只是单层或相邻的两层，忽略了网络中整体传播的影响，思路是用一个神经网络重要性分数传播(NISP)算法，将网络剪枝描述为一个二进制整数优化问题。 实现部分我懒得看了，差不多得了。 Optimal Brain Damage 最佳脑损伤 这篇文章最让我震惊的是它的发表自1990，至今在各种网络中都能取得非常优异剪枝效果。我在最新的一些论文中总是能看到它的影子，具体做法就是计算目标函数对参数求二阶导数，用于表示参数的贡献度，基于贡献度修剪，其中的公式和近似方法先保留，很经典。 Optimal Brain Surgeon and General Network Prunng 最佳脑外科医生和一般网络修剪 OBD的改进版，主要运算方面的改进，递归计算海森矩阵的逆矩阵。 Pruning Filter in Filter 在过滤器中修剪过滤器 作者认为修剪后的结构比权重更为重要，并引入一个可学习矩阵作为滤波器骨架，反应每个滤波器的形状。 Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers 重新思考卷积层通道剪枝中的值小不重要假设 作者对依据范数值大小剪枝做了些讨论，并提出给卷积通道加一个门，来判断该通道有没有起作用。 Strategies for Re-training a Pruned Neural Network in an Edge Computing Paradigm 在边缘计算范式下重新训练修剪神经网络的策略 部署在边缘移动设备之后很难再重新训练，作者提出了剪枝后重训练的概念。 Soft filter pruning for accelerating deep convolutional neural networks 用于加速深度卷积神经网络的软过滤器修剪 一种动态剪枝方法，它能够让被剪掉的过滤器参与一定的训练从而提高剪枝的效率。 The Generalization-Stability Tradeoff In Neural Network Pruning 神经网络剪枝中的泛化-稳定性权衡 文章对泛化展开了一些讨论，最后通过自己的实验得到如下结论：“减少参数量，减少网络对噪声的过拟合，从而提高泛化能力（test acc）” 的说法是不够准确的，因为大网络在不减少参数量的情况下，一样可以有很好的泛化能力，剪枝能提高网络性能的根本原因是在训练过程中引入了训练噪声，从而提高了泛化能力。 Parameter Efficient Training of Deep Convolutional Neural Networks by Dynamic Sparse Reparameterization Hesham Mostafa and Xin Wang, Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization, Proc. Int. Conf. Machine Learning (ICML), 2019. 基于动态稀疏重参数化的深卷积神经网络参数有效训练 训练过程中会动态地改变网络的稀疏结构，取得了优异的性能，作者表明在有限存储和计算预算下训练一个CNN，分配部分资源来描述和演化网络的结构比完全花在一个稠密网络参数上更好。 MLPrune: Multi-Layer Pruning for Automated Neural Network Compression Wenyuan Zeng and Raquel Urtasun. MLPrune: Multi-layer pruning for automated neural network compression, 2019. URL https://openreview.net/forum?id=r1g5b2RcKm. 用于自动神经网络压缩的多层剪枝 基于 Kronecker 因子近似曲率方法，使用 Hessian 的有效近似作为我们的修剪标准。 Exploiting Kernel Sparsity and Entropy for Interpretable CNN Compression Li Y, Lin S, Zhang B, et al. Exploiting Kernel Sparsity and Entropy for Interpretable CNN Compression. 2018. 利用核稀疏性和熵实现可解释CNN压缩 基于KSE指标进一步进行核聚类，实现高精度CNN压缩. 需要硬件支持卷积核稀疏。 Group Fisher Pruning for Practical Network Compression ICML. 2021. 群Fisher修剪在实际网络压缩中的应用 一种分层分组算法，寻找耦合的通道，利用梯度计算的链式原则得到通道的重要性，迭代移除不重要的通道，最后再微调。 =&gt; 理论研究： A Probabilistic Approach to Neural Network Pruning 一种神经网络剪枝的概率方法 提供一种通用的方法在概率意义上限制修剪后的网络和目标网络之间的间隙 2、稀疏惩罚 Fast ConvNets Using Group-wise Brain Damage 使用群体脑损伤的快速卷积网络 没有特别细致的看，不知道是不是最先提出的，以组的方式修剪卷积张量核。 LEARNING SPARSE NEURAL NETWORKS THROUGH L0 REGULARIZATION 通过正则化L0学习稀疏神经网络 主要是提出一种分布来替代L0优化目标函数，类似伯努利分布的推广，但是我偷懒，没有推导下去。 Learning the Number of Neurons in Deep Networks 学习深度神经网络的神经元数量 使用一个稀疏正则化器，让网络变得更紧凑，文中对group lasso求了闭式解，表明最终神经元参数会趋零。 Learning Structured Sparsity in Deep Neural Networks 深度神经网络的结构稀疏性学习 对Lasso的一种推广，即将特征分组后的Lasso，Group Lasso。 Learning Efficient Convolutional Networks through Network Slimming 通过网络瘦身学习高效卷积网络 将L1正则化施加到BN层的缩放因子上，L1正则化推动BN层的缩放因子趋向于零，从而鉴别出不重要的通道或者神经元。 Pruning Filters for Efficient ConvNets 高效卷积网络的剪枝过滤器 采用L1范数来评估CNN中过滤器的重要性，实现模型剪枝。 PRUNE YOUR NEURONS BLINDLY: NEURAL NETWORK COMPRESSION THROUGH STRUCTURED CLASS-BLIND PRUNING 盲目地修剪你的神经元：神经网络通过结构化的类盲修剪进行压缩 标题很装啊，就是L1惩罚稀疏后结构化剪枝，使得网络更紧凑非稀疏。 Sparse Convolutional Neural Networks 稀疏卷积神经网络 矩阵分解加稀疏约束的融合怪罢了 TRAINING COMPRESSED FULLY-CONNECTED NET-WORKS WITH A DENSITY-DIVERSITY PENALTY 用密度-多样性惩罚训练压缩的全连接网络 看标题就知道，文章将全连接层的密度和多样性也加入损失进行惩罚，意图使得网络变得更稀疏多样性更差。 这点与我们角相异惩罚的想法相反，多样性更差意味着特征表达能力更差，精度上不能接受。 Sparse Training via Boosting Pruning Plasticity with Neuroregeneration 稀疏训练:促进修剪可塑性与神经再生 渐进修剪的方法，属于动态剪枝一类 3、对抗剪枝 Towards Optimal Structured CNN Pruning via Generative Adversarial Learning 通过生成对抗学习实现最优结构化 CNN 剪枝 主要思路就是把剪枝网络设为生成器，将输出特征作为Fake，再选一个泛化优异的模型做Baseline，Baseline的输出作为Real，再设计一个全连接层做判别器，最终达到低精度损失的剪枝目的。 这篇很晚才看到，我们前段时间正好做了个类似的实验，还觉得自己对抗剪枝的想法很新颖，做了些相关测试，后来才看到该文献，发现与前人暗合，就放弃了，实在可惜。 4、彩票理论 The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635, 2018. 彩票假设：寻找稀疏的、可训练的神经网络 作者的假设：密集、随机初始化的前馈网络包含子网络(中奖彩票)，当独立训练时，这些子网络在类似的迭代次数中达到与原始网络相当的测试精度。 彩票假说的提出，是对传统“预训练-剪枝-精度恢复”工作流的挑战。在这之前通常认为预训练模型的权重对压缩后模型的精度恢复十分重要，然而彩票理论却认为通过随机初始化权重的子网络仍可以达到原始网络的精度。 作者找到的中奖彩票的原始初始化彩票：它们的连接具有初始权重，这使得训练特别有效。然后提出了一个算法，以确定中奖彩票和一系列的实验，支持彩票假说和这些偶然初始化的重要性。 寻找中奖网络：作者提出了迭代幅值剪枝（IMP，iterative magnitude pruning）方法：首先，对初始的稠密网络进行多轮训练，直到模型收敛。然后确定最小的s%个权值，并创建一个二值掩模对这些权值进行剪枝。随后，使用之前的初始化权值重新训练稀疏化后的网络。在模型收敛后，我们重复该剪枝过程，并使用新一轮剪枝后发现的掩模设置初始化权值。我们重复这个过程，直到达到期望的稀疏程度，或者测试准确率显著下降。 正好我前一段时间思考了这么一个问题，我还是蛮相信缘分的。NeurlPS2020的剪枝相关论文都有提到彩票理论，剪枝邻域的探索还在继续。（好好看好好学） 围绕彩票假设的扩展研究： Evaluating lottery tickets under distributional shifts Shrey Desai, Hongyuan Zhan, and Ahmed Aly. Evaluating lottery tickets under distributional shifts. In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019), pages 153–162, 2019. 评估分配转移下的彩票 作者集中于评估分布移位下稀疏子网络的初始化，研究在源域中获得的稀疏子网络可以在不同的目标域中隔离地重新训练的程度，另外也考察了不同初始化策略在传输时的效果。最后表明，通过彩票训练获得的稀疏子网络并不是简单地过度适合于特定领域，而是反映了深层神经网络的诱导偏差，可以在多个领域中加以利用。 Stabilizing the Lottery Ticket Hypothesis Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Stabilizing the lottery ticket hypothesis. arXiv preprint arXiv:1903.01611, 2019. 稳定彩票假说 IMP在更深层的网络中很难得到子网络，作者对其进行了改进，比如在训练早期修剪，但不是最开始。另外作者研究了子网的稳定性，提供了新见解。 One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers Ari S Morcos, Haonan Yu, Michela Paganini, and Yuandong Tian. One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers. stat, 1050:6, 2019. 作者通过为一种训练配置（优化器和数据集）生成中奖券并评估中奖网络在另一种配置上的性能。由足够大的数据集生成的中奖彩票初始化包含更广泛地适用于神经网络的归纳偏差，这改进了许多设置的训练，并为开发更好的初始化方法提供了希望。 Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask Hattie Zhou, Janice Lan, Rosanne Liu, and Jason Yosinski. Deconstructing lottery tickets: Zeros, signs, and the supermask. arXiv preprint arXiv:1905.01067, 2019. 解构彩票：零、符号和超级面具 彩票网络假设的维护派，对其算法进行了分析，消除一些影响因素。另外展示了为什么要把权重置零，以及一些系列重要做法。 Proving the Lottery Ticket Hypothesis: Pruning is All You Need Eran Malach, Gilad Yehudai, Shai Shalev-Schwartz, and Ohad Shamir. Proving the lottery ticket hypothesis: Pruning is all you need. In International Conference on Machine Learning, pages 6682–6691. PMLR, 2020. 证明彩票假设：你需要修剪 作者从理论上证明了彩票假说，表明对于每个有界分布和每个具有有界权重的目标网络，具有随机权重的充分过度参数化的神经网络包含的子网络大致为与目标网络相同的精度，无需任何进一步的训练。 （代细读 Slot Machines: Discovering Winning Combinations of Random Weights in Neural Networks 老虎机:发现神经网络中随机权重的获胜组合 作者发现仅为每个连接分配少量的随机值，不通过训练，模型也能表现出不错的性能。如果每个连接都有足够的随机权重选项，就存在这些随机权重值的选择，其泛化性能可与具有相同架构的传统训练网络相媲美。 这是个很有趣的现象，也进一步证明了神经网络巨大的表达能力。 （待深入研究） Efficient Lottery Ticket Finding: Less Data is More 高效彩票发现：数据越少越好 深层网络的样本要么在训练时难以记忆，要么在修剪时很容易忘记。作者设定修剪感知临界集合（PrAC）来选取特定的样本，实现高效彩票发现。 Rigging the Lottery: Making All Tickets Winners 操纵彩票：让所有彩票中奖 动态剪枝的方法，算法分四个部分：稀疏分布，更新计划，删除标准，增长标准。 具体来说：余弦衰减更新稀疏率，删除小权重，添加最大梯度的权重，循环。 作者也尝试了选择梯度方向最小值来激活连接，但没有取得好效果。读到这里时我是比较无语的，因为我现在做的骨架填充和置换就是这个思路，就摁卷吧。 Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training 我们真的需要稠密的参数化吗？稀疏训练时间序列上的过参数 提出的时间序列过参数很有新意，虽然就是给动态剪枝换个概念。文中大量的实验和解释，各种因素的影响。 Connectivity Matters: Neural Network Pruning Through the Lens of Effective Sparsity 连通性问题：通过有效稀疏性的透镜修剪神经网络 从有效压缩入手（有效稀疏度，一般稀疏度），即我们做的核链（服了）。主要考虑层比例，不像SNIP,GraSP一样的层分布。 后面的两个做法不是很明白（二分法确定压缩率？），有时间复现下再补充。 质疑彩票假设： Rethinking the Value of Network Pruning Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. Rethinking the value of network pruning. In International Conference on Learning Representations, 2018. 重新思考网络剪枝的价值 作者检查了六种先进的剪枝算法，得到的结果：1）训练一个大的、过度参数化的模型不是获得有效的最终模型所必需的，2）大模型的学习“重要”权重不一定对小剪枝模型有用，3）修剪后的架构本身，而不是一组继承的“重要”权重，是导致最终模型效率提高的原因，这表明某些修剪算法可以被视为执行网络架构搜索。 The State of Sparsity in Deep Neural Networks Trevor Gale, Erich Elsen, and Sara Hooker. The state of sparsity in deep neural networks. arXiv preprint arXiv:1902.09574, 2019. 深度神经网络中的稀疏状态 作者大规模复制了彩票假设的实验，并表明通过剪枝学习的非结构化稀疏架构无法从头开始训练到与训练模型相同的测试集性能联合稀疏化和优化。 对此作者很生气😡，开源了代码，并给出模型最好的状态，以便未来压缩和稀疏化工作建立严格的基线。 （代细读） Comparing Rewinding and Fine-tuning in Neural Network Pruning Alex Renda, Jonathan Frankle, and Michael Carbin. Comparing rewinding and fine-tuning in neural network pruning. arXiv preprint arXiv:2003.02389, 2020. 比较神经网络修剪中的回绕和微调 《比较》 =&gt; 初始化时修剪： SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr. Snip: Single-shot network pruning based on connection sensitivity. International Conference on Learning Representations, ICLR, 2019. 基于连接敏感度的单次网络剪枝 19年的一篇会议论文，作者提到现有的方法破坏了网络的效用，不能保持原网络的性能，而且剪枝再训练的过程极其繁琐。他们设计了一个标准，以数据相关的方式直接衡量连接的重要性，减少了对权值的依赖，一开始就对网络进行一次剪枝，然后在稀疏剪枝后的网络上进行训练。 具体做法就是定义一个辅助矩阵来做剪枝标记，根据剪掉和保留导致的损失值变化来确定其网络的连接，按照需求的剪枝率保留损失值变化大的，最后近似成把导数大小（无论符号）作为对损失的影响，所以根据导数来设定权重分数进行修剪。 一些细节问题： 初始化权重对损失值变动影响很大，所以初始化的时候要注意梯度在合理的范围，整个网络方差保持不变具有更好鲁棒性。 损失值变化与数据集关系也很大，作者说选取小批量数据就可 PICKING WINNING TICKETS BEFORE TRAINING BY PRESERVING GRADIENT FLOW Chaoqi Wang, Guodong Zhang, and Roger Grosse. Picking winning tickets before training by preserving gradient flow. In International Conference on Learning Representations, 2019. 通过保持梯度流在训练前挑选中奖彩票 作者定义一个称之为梯度信号保持的剪枝标准，是基于SNIP和彩票假设的一种扩展，SNIP只考虑一个权重的梯度，容易删除一些重要的连接，彩票假设需要重复的训练。 做法是将梯度再进行一次微分，相当于根据损失值的变化率来评估，称保持梯度流，用泰勒近似来求解的，公式这一块没有SNIP清晰（简单）。 虽然GraSP一定程度上保证了高压缩率下的性能，但比不过迭代考虑层连接的剪枝方案，另外对梯度范数敏感处理GraSP也存在问题，这点在我的论文中有所改进。 Pruning via Iterative Ranking of Sensitivity Statistics Stijn Verdenius, Maarten Stol, and Patrick Forré. Pruning via iterative ranking of sensitivity statistics. arXiv preprint arXiv:2006.00896, 2020. 通过敏感性统计的迭代排序进行修剪 SNIP的迭代应用。 ESPN: Extremely Sparse Pruned Networks Minsu Cho, Ameya Joshi, and Chinmay Hegde. Espn: Extremely sparse pruned networks. arXiv preprint arXiv:2006.15741, 2020. ESPN：非常稀疏的修剪网络 单次网络修剪方法（如 SNIP）与彩票类型方法之间的混合方法 论文中的实验数据很牛逼，代研究。 PROGRESSIVE SKELETONIZATION: TRIMMING MORE FAT FROM A NETWORK AT INITIALIZATION Pau de Jorge, Amartya Sanyal, Harkirat S Behl, Philip HS Torr, Gregory Rogez, and Puneet K Dokania. Progressive skeletonization: Trimming more fat from a network at initialization. arXiv preprint arXiv:2006.09081, 2020. 渐进式骨骼化：初始化时从网络中修剪更多冗余 基于SNIP的扩展，作者表明稀疏程度超过95%的网络很难保持性能，甚至比随机修剪的网络还差，提出骨架化网络（网络骨架的意思）。一方面迭代SNIP，允许前期不重要的权重在后期变得重要；另一方面允许已经删减的权重能够恢复。 目前来说，迭代过的方案都违背了训练前修剪的初衷。 =&gt; 更深的理论研究： A Signal Propagation Perspective for Pruning Neural Networks at Initialization Namhoon Lee, Thalaiyasingam Ajanthan, Stephen Gould, and Philip HS Torr. A signal propagation perspective for pruning neural networks at initialization. In International Conference on Learning Representations, 2019. 基于信号传播的神经网络初始化剪枝方法 为什么修剪一个未经训练的、随机初始化的神经网络是有效的还不清楚。作者通过将连接敏感度作为梯度的形式，正式描述了初始化条件，以确保可靠的连接敏感度测量，从而产生有效的修剪结果。 作者证明了保证连通敏感度的充分条件是分层动态等距。修剪网络会破坏动态等距，所以提出了一种无数据方法来恢复给定稀疏拓扑的分层正交性。 等等（代细读）。 Pruning neural networks without any data by iteratively conserving synaptic flow Hidenori Tanaka, Daniel Kunin, Daniel L Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. Advances in Neural Information Processing Systems, 33, 2020. 通过迭代保存突触流在没有任何数据的情况下修剪神经网络 作者提出找到稀疏网络不需要训练，或者不需要查看数据，他们从数学上推导并通过实验验证了一个守恒定律，解释了现有的基于梯度修剪算法为什么初始化时会导致层崩溃，该理论还阐明了如何完全避免层崩溃，从而激发了一种新的修剪算法――迭代突触流修剪（SynFlow）。 文中的两个假设：剪枝的临界压缩等于网络的最大压缩；层大小和平均层分数之间成反比。 突触显著性(Synaptic saliency)：一类分数指标，梯度与参数的阿达玛积。 文中证明出的定理： 突触显著性的神经元守恒 突触显著性的网络守恒 迭代、积极和保守的评分实现了最大的临界压缩 守恒和迭代修剪可避免层崩溃 重新定义一个与数据无关的损失函数 Logarithmic Pruning is All Y ou Need Orseau L, Hutter M, Rivasplata O. Logarithmic Pruning is All You Need. 2020. 你需要对数修剪 自彩票假说之后提出了很多假说，本文否定了很多假设，提供了更严格的界限：超参数化网络只需要每个目标子网络权重的对数因子神经元数（除深度之外的所有变量）。前面的意思就是可以得到一个对数因子来确定剪枝网络的参数量，作者进行了很多证明和推导，不过我没整明白。 ROBUST PRUNING AT INITIALIZATION Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, and Yee Whye Teh. Robust pruning at initialization. 初始化时的健壮修剪 作者使用原则性的缩放和重新参数化来解决极限修剪时的层崩塌问题，其中提出的EOC初始化方法有待考究，原文相当的长，附录中有大量的推导，对于我来说还是太早了。 Finding trainable sparse networks through Neural Tangent Transfer Tianlin Liu and Friedemann Zenke. Finding trainable sparse networks through neural tangent transfer. In International Conference on Machine Learning, 2020. 作者介绍了神经切线转移，这是一种以无标签方式寻找可训练稀疏网络的方法。依据稀疏网络的训练动态，以神经切线核为特征，模仿函数空间中密集网络的训练动态。 （代细读） =&gt; 单次修剪的质疑： PRUNING NEURAL NETWORKS AT INITIALIZATION: WHY ARE WE MISSING THE MARK? Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Pruning neural networks at initialization: Why are we missing the mark? arXiv preprint arXiv:2009.08576, 2020. 在初始化时修剪神经网络：为什么我们忽略了掩码？ 作者质疑了SNIP，GraSP和SynFlow，初始化删减是否对性能有限制，并评估了这些方法在初始化时的有效性。 （代细读） *、网络压缩相关（剪枝之后的进一步压缩方法） Binarized neural networks Training deep neural networks with weights and activations constrained to+ 1 or-1 二值化神经网络：训练神经网络的权值和激活约束为+1或−1 这是2016年的一篇关于模型量化的文章，在网络量化中，有一种极为诱惑的量化方式：1bit量化——极致的压缩！但是1bit的网络在训练时有诸多细节需要完善。 通过简单的二值化函数，前向传播时权重会与一个权重系数相乘，反向传播时先更新之后再量化。 其中BN操作和其他优化的乘法可以用位移操作来代替，加快运算速度。 DEEP COMPRESSION: COMPRESSING DEEP NEURAL NETWORKS WITH PRUNING, TRAINED QUANTIZATION AND HUFFMAN CODING 深度压缩：通过剪枝、训练量化和霍夫曼编码对深度神经网络进行压缩 首先权重剪枝（小于阈值的剪掉，压缩稀疏行/列储存），然后量化和权重共享（聚类方法），最后Huffman Coding进一步压缩。 通过这三阶段的压缩，直接进行一个敌的无。 Learning both Weights and Connections for Efficient Neural Networks 学习权重和有效的神经网络连接 剪枝三步走，训练、剪枝、重训练。 Predicting Parameters in Deep Learning 预测深度学习中的参数 说的好听，其实是低秩近似的方法，over。 Pruning Convolutional Neural Networks for Resource Efficient Transfer Learning 剪枝卷积神经网络在资源高效传输中的应用 论文中提出了一个基于泰勒展开的新准则，用它去近似由于修剪网络参数引起的损失函数的变化。 文中有不少巧妙的细节，值得学习，保留。 #、---","link":"/2021/05/04/13/clgj6ojki001ussika2kj3day/"},{"title":"神经网络解释和理解相关论文","text":"==&gt;==&gt; 快进到2077 ==&gt;==&gt; 可解释性 —— 人工智能过不去的一道坎 志大才疏，待续， 预训练 从剪枝做到可解释性预训练，只能说望尘莫及。 预训练模型 图像领域：ImageNet训练的模型迁移到下游任务 NLP领域：包含上下文信息的BERT预训练模型 预训练的应用（特征迁移和参数迁移） 特征提取。去掉预训练模型的输出层，做为固定的特征提取机。 冻结特定层，只训练后面的层。ALBERT: https://arxiv.org/abs/1909.11942 多模态融合 ViLBERT: https://arxiv.org/abs/1908.02265 ImageBERT: https://arxiv.org/abs/2001.07966 预训练的解释 两个假设来解释预训练的效果：（1）更好的优化（2）更好的正则化。 (2010)Why Does Unsupervised Pre-training Help Deep Learning? 引入了潜在类的概念，弥合预训练和微调之间的差距。（迁移到下游时可以有更低的loss） (2019)A Theoretical Analysis of Contrastive Unsupervised Representation Learning 泛化 Stronger generalization bounds for deep nets via a compression approach 通过压缩方法使深度神经网络获得更强泛化能力 作者为压缩网络提升泛化提供了一些理论依据，提出一个证明泛化边界的简单压缩框架，提出识别网络中噪声的方法。 Generalization and Expressivity for Deep Nets 深度神经网络的泛化和表达 作者发现深网具有良好的表达能力(通过局部和稀疏逼近来衡量)，而没有本质上扩大浅网的容量。基于这个结论，作者得出经验风险最小化(ERM)的最优学习率。 #、---","link":"/2021/09/23/15/clgj6ojlr0055ssik3h3saxc5/"},{"title":"大语言模型","text":"AGI的火花 一篇很好的综述：大型语言模型（LLM）技术精要 大语言模型调研汇总 GPT pass LaMDA pass PaLM pass GLM-130B 清华中英双语语言模型，在量化方面有优势，开源。 LLaMA Meta AI推出了大语言模型LLaMA，包括7B、13B、33B和65B几个版本，与GPT3性能相当。 10G显存可跑：8-bit LLaMA 7B，4-bit LLaMA 7B，4-bit LLaMA 13B 。 测试了7B模型，效果一般，需要针对性微调。 羊驼家族 LLaMA的模型泄漏诞生了羊驼家族：Alpaca、Vicuna、Koala、ChatLLaMA 、FreedomGPT、ColossalChat...，基本上都是指令微调的结果。 Alpaca 由LLaMA 7B微调而来，仅用52k数据，训练成本低 Alpaca-LoRA LoRA微调 Alpaca-ChToken and Luotuo 中文token，Luotuo的开源做得很好 Vicuna Vicuna-13B接近Bard FreedomGPT 输出不受限制的AI模型，Freedom! 大模型的研究热点 LLaMA的轻量级版本和微软开源的Deep Speed Chat很大程度降低了大语言模型的门槛，相关的研究和应用已是呈爆炸式增长。 大模型的微调 提示学习（prompt learning） 指令学习（instruction learning） LoRA微调（Alpaca-LoRA） 大模型的压缩和加速 SparseGPT Compression for AGI 大模型的能力涌现和多模态 不存在了，可解释性不存在了! Kosmos-1 PALM-E Visual ChatGPT LLM = Compression OpenAI的新观点：大语言模型的本质，其实是一个性能强大的数据无损压缩器。 ... 个人想法 目前大模型的能力及其惊人，模型轻量化必然是现有阶段的关键环节。个人感觉大模型蒸馏和剪枝的方法即将遍地开花（前几年在预训练模型上的蒸馏就很多），虽然大模型的训练成本依旧很高，但大模型压缩绝对是有利可图的热点领域。 下游任务微调过程中的修剪 依据模型对数据的敏感修剪网络，应用到特定小场景。如：将LLaMA大模型修剪为只写投标文件的小模型（指令学习+剪枝）。 参考一些针对Transformer模型的修剪 基于预训练模型的修剪 类似于训练前修剪的研究，甚至修剪后不做训练，也可以针对特定场景。 LoRA的变体 LoRA实在是太有效了，LoRA和剪枝的结合 利用大模型对轻量模型的蒸馏设计 如用chatgpt做评估训练一个轻量的问答系统 顺着大模型的思路去，设计大模型来修剪大模型，修剪一切！ 瞎扯一下，大模型可以Segment Anything，大模型也可以Pruning Anything！","link":"/2023/04/20/19/clgp0y2e80000y4ikbhvze5y4/"}],"tags":[{"name":"AI工具","slug":"AI工具","link":"/tags/AI%E5%B7%A5%E5%85%B7/"},{"name":"人工智能","slug":"人工智能","link":"/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"神经网络","slug":"神经网络","link":"/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"市场调研","slug":"市场调研","link":"/tags/%E5%B8%82%E5%9C%BA%E8%B0%83%E7%A0%94/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"博客","slug":"博客","link":"/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"服务器","slug":"服务器","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Gazebo","slug":"Gazebo","link":"/tags/Gazebo/"},{"name":"PX4","slug":"PX4","link":"/tags/PX4/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Google Colab","slug":"Google-Colab","link":"/tags/Google-Colab/"},{"name":"自然语言处理","slug":"自然语言处理","link":"/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"},{"name":"ROS","slug":"ROS","link":"/tags/ROS/"},{"name":"仿真","slug":"仿真","link":"/tags/%E4%BB%BF%E7%9C%9F/"},{"name":"VsCode","slug":"VsCode","link":"/tags/VsCode/"},{"name":"LaTeX","slug":"LaTeX","link":"/tags/LaTeX/"},{"name":"深度学习平台","slug":"深度学习平台","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0/"},{"name":"白嫖","slug":"白嫖","link":"/tags/%E7%99%BD%E5%AB%96/"},{"name":"xx","slug":"xx","link":"/tags/xx/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"Neural Network","slug":"Neural-Network","link":"/tags/Neural-Network/"},{"name":"哲思","slug":"哲思","link":"/tags/%E5%93%B2%E6%80%9D/"},{"name":"硅基生命","slug":"硅基生命","link":"/tags/%E7%A1%85%E5%9F%BA%E7%94%9F%E5%91%BD/"},{"name":"作战系统","slug":"作战系统","link":"/tags/%E4%BD%9C%E6%88%98%E7%B3%BB%E7%BB%9F/"},{"name":"军事装备","slug":"军事装备","link":"/tags/%E5%86%9B%E4%BA%8B%E8%A3%85%E5%A4%87/"},{"name":"美军","slug":"美军","link":"/tags/%E7%BE%8E%E5%86%9B/"},{"name":"c++","slug":"c","link":"/tags/c/"},{"name":"算法题","slug":"算法题","link":"/tags/%E7%AE%97%E6%B3%95%E9%A2%98/"},{"name":"强化学习","slug":"强化学习","link":"/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"Reinforcement Learning","slug":"Reinforcement-Learning","link":"/tags/Reinforcement-Learning/"},{"name":"图像处理","slug":"图像处理","link":"/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"机器视觉","slug":"机器视觉","link":"/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"},{"name":"深度框架","slug":"深度框架","link":"/tags/%E6%B7%B1%E5%BA%A6%E6%A1%86%E6%9E%B6/"},{"name":"CUDA编程","slug":"CUDA编程","link":"/tags/CUDA%E7%BC%96%E7%A8%8B/"},{"name":"模型泛化","slug":"模型泛化","link":"/tags/%E6%A8%A1%E5%9E%8B%E6%B3%9B%E5%8C%96/"},{"name":"管理体系","slug":"管理体系","link":"/tags/%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/"},{"name":"神经网络剪枝","slug":"神经网络剪枝","link":"/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%89%AA%E6%9E%9D/"},{"name":"大语言模型","slug":"大语言模型","link":"/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"}],"categories":[{"name":"浮生日记","slug":"浮生日记","link":"/categories/%E6%B5%AE%E7%94%9F%E6%97%A5%E8%AE%B0/"},{"name":"码农笔记","slug":"码农笔记","link":"/categories/%E7%A0%81%E5%86%9C%E7%AC%94%E8%AE%B0/"},{"name":"学习日志","slug":"学习日志","link":"/categories/%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/"},{"name":"xx","slug":"xx","link":"/categories/xx/"}],"pages":[]}